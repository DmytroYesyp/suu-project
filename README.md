Knative \- OTel
==============

[GoogleDocs](https://docs.google.com/document/d/1zVsoGiIb50rPzTMCSIOD62AAp-FyuXdTZhBHDyCoWtY/edit?tab=t.0)


**Jan ChyczyÅ„ski, Kacper Kozak, Dmytro Yesyp, BartÅ‚omiej SÅ‚upik**

# Wprowadzenie

Ten projekt demonstruje praktyczne zastosowanie Knative na przykÅ‚adzie zmodyfikowanej aplikacji Bookstore â€“ prostej ksiÄ™garni internetowej dziaÅ‚ajÄ…cej w architekturze event-driven. Aplikacja zostaÅ‚a rozszerzona o mechanizmy obsÅ‚ugi bÅ‚Ä™dÃ³w, takie jak retry i dead letter sink, oraz zintegrowana z OpenTelemetry i GrafanÄ… w celu monitorowania przepÅ‚ywu zdarzeÅ„. Projekt ilustruje kluczowe cechy Knative, takie jak przetwarzanie zdarzeÅ„, elastyczne skalowanie oraz niezawodna obsÅ‚uga niepowodzeÅ„, dajÄ…c jednoczeÅ›nie wglÄ…d w dziaÅ‚anie systemu dziÄ™ki wizualizacji metryk i Å›ledzeniu zdarzeÅ„ w czasie rzeczywistym.

# Podstawy teoretyczne i opis stosu technologicznego

Knative to system, ktÃ³ry pomaga deweloperom w zarzÄ…dzaniu i utrzymywaniu procesÃ³w w Kubernetes. Jego celem jest uproszczenie, zautomatyzowanie i monitorowanie wdroÅ¼eÅ„ w Kubernetes, aby zespoÅ‚y spÄ™dzaÅ‚y mniej czasu na konserwacji, a wiÄ™cej na tworzeniu aplikacji i realizacji projektÃ³w. Knative przejmuje powtarzalne i czasochÅ‚onne zadania, eliminujÄ…c wÄ…skie gardÅ‚a i opÃ³Åºnienia.

Te zaÅ‚oÅ¼enia realizowane sÄ… za pomocÄ… dwÃ³ch funkcji. Pierwsza to **Knative Eventing**, ktÃ³ra pozwala deweloperom definiowaÄ‡ akcje wyzwalane przez okreÅ›lone zdarzenia zachodzÄ…ce w szerszym Å›rodowisku. Druga to **Knative Serving**, ktÃ³ra automatycznie zarzÄ…dza tworzeniem oraz skalowaniem usÅ‚ug w Kubernetes, wÅ‚Ä…cznie ze skalowaniem do zera. Obie te funkcje majÄ… na celu uwolnienie zasobÃ³w, ktÃ³re zespoÅ‚y normalnie musiaÅ‚yby przeznaczyÄ‡ na zarzÄ…dzanie systemami. Dodatkowo przynoszÄ… one oszczÄ™dnoÅ›ci finansowe, reagujÄ…c na zmieniajÄ…ce siÄ™ warunki w czasie rzeczywistym, wÅ‚Ä…czajÄ…c w to â€œskalowanie do zeraâ€  â€” firmy pÅ‚acÄ… tylko za zasoby, ktÃ³re faktycznie wykorzystujÄ…, a nie za te, ktÃ³re mogÅ‚yby potencjalnie zuÅ¼yÄ‡.

Kluczowa idea Knative polega na umoÅ¼liwieniu zespoÅ‚om wykorzystania potencjaÅ‚u bezserwerowego wdraÅ¼ania aplikacji. â€Serverlessâ€ odnosi siÄ™ do zarzÄ…dzania serwerami i maszynami wirtualnymi w chmurze, czÄ™sto udostÄ™pnianymi przez platformy takie jak AWS, Google Cloud czy Microsoft Azure. Serverless to doskonaÅ‚e rozwiÄ…zanie dla firm, ktÃ³re chcÄ… odejÅ›Ä‡ od kosztownego utrzymywania wÅ‚asnych serwerÃ³w i infrastruktury.

**OpenTelemetry** to otwarty standard oraz zbiÃ³r narzÄ™dzi, bibliotek i API, stworzony w celu zbierania danych telemetrycznych z oprogramowania. Jego gÅ‚Ã³wnym celem jest standaryzacja sposobu instrumentowania aplikacji, umoÅ¼liwiajÄ…c deweloperom gromadzenie danych o wykonywaniu kodu, niezaleÅ¼nie od uÅ¼ywanego jÄ™zyka programowania czy frameworku, a takÅ¼e niezaleÅ¼nie od systemu monitorowania, ktÃ³ry bÄ™dzie te dane analizowaÅ‚ i wizualizowaÅ‚ (takich jak Grafana, Prometheus, Jaeger itp.).

OpenTelemetry koncentruje siÄ™ na trzech gÅ‚Ã³wnych typach telemetrii: Å›ladach (traces), ktÃ³re Å›ledzÄ… drogÄ™ Å¼Ä…dania przez rozproszony system; metrykach (metrics), ktÃ³re mierzÄ… wskaÅºniki wydajnoÅ›ci (np. liczbÄ™ Å¼Ä…daÅ„, czas odpowiedzi, wykorzystanie zasobÃ³w); oraz logach (logs), ktÃ³re rejestrujÄ… zdarzenia w aplikacji. IntegrujÄ…c biblioteki OpenTelemetry ze swoim kodem, "instrumentujesz" go, aby automatycznie lub zgodnie z Twoimi wytycznymi generowaÅ‚ te dane. NastÄ™pnie dane te mogÄ… byÄ‡ eksportowane (za poÅ›rednictwem OpenTelemetry Collector lub bezpoÅ›rednio) do rÃ³Å¼nych systemÃ³w backendowych w celu przechowywania, analizy, wizualizacji i alertowania, co zapewnia gÅ‚Ä™bokie zrozumienie dziaÅ‚ania systemu, lokalizacjÄ™ problemÃ³w i ich rozwiÄ…zywanie.

**GÅ‚Ã³wne cechy Knative:**

* Automatyczne skalowanie w oparciu o obciÄ…Å¼enie ruchem. Wprowdza skalowanie do zera, pozwalajÄ…ce zmniejszyÄ‡ uÅ¼ycie zasobÃ³w.  
* Natywne wsparcie dla architektury Event-driven, ktÃ³ra w samym Kubernetesie wymaga uÅ¼ycia zewnÄ™trznego narzÄ™dzia takiego jak RabbitMQ czy Kafka.  
* â€œRevisionsâ€ \- knative tworzy snapshoty serwisÃ³w i ich konfiguracji co uÅ‚atwia operacje takie jak rollback i wersjonowanie.  
* Traffic splitting \- pozwala trasowaÄ‡ ruch na wiele â€œrevisionsâ€ w prosty sposÃ³b wspierajÄ…c â€œCanary releaseâ€ czy A/B testing.  
* UÅ‚atwia development wprowadzajÄ…c CRD â€œServiceâ€, zastÄ™pujÄ…cy Deploymenty/Statefulsety i obsÅ‚ugujÄ…cy routing czy scalling co w czystym kubernetesie wymagaÅ‚oby zdefiniowania i skonfigurowania dodatkowych zasobÃ³w.  
* Wbudowane trasowanie \- automatyczne generowanie tras HTTP z moÅ¼liwoÅ›ciÄ… dostosowania domen.

Knative posiada rÃ³wnieÅ¼ wbudowane mechanizmy obsÅ‚ugi bÅ‚Ä™dÃ³w, ktÃ³re zwiÄ™kszajÄ… niezawodnoÅ›Ä‡ architektury event-driven. W przypadku gdy dostarczenie zdarzenia do jednej z usÅ‚ug zakoÅ„czy siÄ™ niepowodzeniem, moÅ¼liwe jest automatyczne ponawianie prÃ³b zgodnie z konfigurowalnÄ… politykÄ… retry. JeÅ›li mimo prÃ³b dostarczenie siÄ™ nie powiedzie, zdarzenie moÅ¼e zostaÄ‡ przekierowane do tzw. *Dead Letter Sink* â€” specjalnego komponentu, ktÃ³ry przechowuje lub loguje zdarzenia niedostarczone. DziÄ™ki temu Å¼adne dane nie zostajÄ… utracone, a deweloperzy mogÄ… Å‚atwo analizowaÄ‡ przyczyny niepowodzeÅ„.

### Stos technologiczny

Projekt oparty jest na Kubernetes i wykorzystuje Knative do zarzÄ…dzania usÅ‚ugami i przetwarzania zdarzeÅ„ w architekturze event-driven. Backend aplikacji zbudowany jest w Node.js, interfejs uÅ¼ytkownika w Next.js, a dane przechowywane sÄ… w PostgreSQL. Przetwarzanie komentarzy realizujÄ… funkcje Knative wykorzystujÄ…ce modele ML do analizy sentymentu i filtrowania treÅ›ci. Do monitorowania systemu zastosowano OpenTelemetry oraz GrafanÄ™, umoÅ¼liwiajÄ…c wizualizacjÄ™ przepÅ‚ywu zdarzeÅ„ i metryk zwiÄ…zanych z obsÅ‚ugÄ… bÅ‚Ä™dÃ³w.

# Koncepcja projektu

[Knative Bookstore Code Samples: GitHub Aplikacja Bookstore](https://github.com/knative/docs/tree/main/code-samples/eventing/bookstore-sample-app/solution)

Opis katalogu â€solutionâ€ przykÅ‚adowej aplikacji Knative Bookstore â€“ w peÅ‚ni zaimplementowanego, event-driven sklepu z ksiÄ…Å¼kami opartego na Knative Eventing. Kod ÅºrÃ³dÅ‚owy dostÄ™pny jest tutaj:

#### **Struktura**

1. **bad-word-filter/**  
    Funkcja Knative filtrujÄ…ca nieodpowiednie treÅ›ci w komentarzach.

2. **db-service/**  
    UsÅ‚uga bazodanowa przechowujÄ…ca recenzje i komentarze do ksiÄ…Å¼ek.

3. **frontend/**  
    Interfejs uÅ¼ytkownika aplikacji Bookstore, zbudowany w Next.js.

4. **node-server/**  
    Serwer Node.js obsÅ‚ugujÄ…cy zaplecze (backend) aplikacji.

5. **sentiment-analysis-app/**  
    Funkcja Knative analizujÄ…ca sentyment recenzji ksiÄ…Å¼ek.

6. **sequence/**  
    Konfiguracja Knative Sequence do orkiestracji przepÅ‚ywu zdarzeÅ„ miÄ™dzy komponentami.

7. **slack-sink/**  
    Integracja z Slack (Apache Camel) wysyÅ‚ajÄ…ca powiadomienia o nowych recenzjach.

<br>
<img src='images/image1.png'>
<br>

## Modyfikacja aplikacji Bookstore (Knative Eventing)

W ramach naszego projektu dokonamy rozszerzenia aplikacji demonstracyjnej Bookstore, opartej na architekturze event-driven z wykorzystaniem Knative. GÅ‚Ã³wnym celem tej modyfikacji jest zaprezentowanie mechanizmÃ³w obsÅ‚ugi bÅ‚Ä™dÃ³w w systemie przesyÅ‚ania zdarzeÅ„, takich jak ponowne prÃ³by (retry) i obsÅ‚uga zdarzeÅ„ niedostarczalnych (dead-letter sink â€“ DLS). Dodamy teÅ¼Â observability w postaci Grafany poÅ‚Ä…czonej przez Prometheus z OpenTelemetry.

1. **Symulacja bÅ‚Ä™dÃ³w w usÅ‚udze Slack Sink:**

   * Wprowadzimy losowÄ… awaryjnoÅ›Ä‡ (np. zwracanie bÅ‚Ä™du HTTP 500\) w komponencie slack-sink, ktÃ³ry odpowiada za wysyÅ‚kÄ™ powiadomieÅ„ do Slacka.

   * Celem jest wymuszenie sytuacji, w ktÃ³rych zdarzenia nie sÄ… poprawnie przetwarzane.

2. **Dodanie mechanizmu Dead Letter Sink:**

   * Utworzymy osobny komponent (Knative Service), ktÃ³ry bÄ™dzie odbiorcÄ… zdarzeÅ„, ktÃ³re nie zostaÅ‚y pomyÅ›lnie dostarczone po okreÅ›lonej liczbie prÃ³b.

   * Zostanie on przypisany jako deadLetterSink w konfiguracji brokera (lub triggera).

3. **Konfiguracja polityki retry i backoff:**

   * Skonfigurujemy parametry retry w Knative Eventing (liczbÄ™ prÃ³b, politykÄ™ opÃ³ÅºnieÅ„).

   * UmoÅ¼liwi to demonstracjÄ™ automatycznego ponawiania dostarczania zdarzeÅ„ w przypadku niepowodzenia.

4. **ObserwowalnoÅ›Ä‡ i monitoring:**

   * WdroÅ¼ymy eksportery OpenTelemetry w kluczowych komponentach.

   * DziÄ™ki temu moÅ¼liwa bÄ™dzie analiza tras zdarzeÅ„, czasÃ³w przetwarzania, liczby prÃ³b oraz przypadkÃ³w przekierowania do DLS.


### **Wykorzystanie Kameleta do symulacji bÅ‚Ä™dÃ³w i obsÅ‚ugi przez Dead Letter Sink**

Zastosujemy Kamelet jako komponent poÅ›redniczÄ…cy, ktÃ³rego zadaniem bÄ™dzie celowe odrzucanie czÄ™Å›ci wiadomoÅ›ci. Celem jest wygenerowanie bÅ‚Ä™dÃ³w dostarczania, ktÃ³re trafiÄ… nastÄ™pnie do Dead Letter Sink (DLS), gdzie zostanÄ… przekazane do OpenTEL w celu zwizualizowania ich w Grafanie.

#### **Mechanizm dziaÅ‚ania:**

1. Kamelet zostanie zaimplementowany jako konsument wiadomoÅ›ci (sink), ktÃ³ry jako odpowiedÅº na co 5 wiadomoÅ›Ä‡ zwraca wyjÄ…tek..

2. W przypadku zwrÃ³cenia wyjÄ…tku przez Kameleta, Knative Eventing automatycznie podejmieÅ‚ prÃ³bÄ™ ponownego dostarczenia wiadomoÅ›ci zgodnie z politykÄ… *retry*.

3. Po przekroczeniu limitu prÃ³b, wiadomoÅ›Ä‡ zostanie przekierowana do wczeÅ›niej zdefiniowanego *Dead Letter Logger*, ktÃ³rym bÄ™dzie osobny Knative Service odpowiedzialny za logowanie bÅ‚Ä™dÃ³w. OdwoÅ‚anie do tego serwisu bÄ™dzie zdefiniowane jako *deadLetterSink* brokera *badword-broker (slack-sink/config/100-broker.yaml).*

4. DLS przekaÅ¼e informacje o nieudanych zdarzeniach do Grafany za poÅ›rednictwem zintegrowanego systemu monitoringu w standardzie Open Telemetry.

<br>
<img src='images/image3.png'>
<br>


# Architektura RozwiÄ…zania

### <br>
<img src='images/image2.png'>
<br>


Architektura Systemu Systemu Knative \- OTel (Zmodyfikowana)

## Implementacja modyfikacji aplikacji Bookstore

### Uproszczenie aplikacji

<br>
<img src='images\kamel.png'>
<br>

Z powodu przestarzaÅ‚oÅ›ci, niezgodnoÅ›ci wersji i problemÃ³w z konfiguracjÄ… (a szczegÃ³lnie konfiguracjÄ… Camel-K co obrazuje powyÅ¼sza infografika) postanowiono usunaÄ‡ nastÄ™pujÄ…ce serwisy:
* slack-sink (zastÄ…piony przez file-sink)
* bad-word-filter (zbÄ™dny dla gÅ‚Ã³wnej idei projektu)
* sentiment-analysis-app (zbÄ™dny dla gÅ‚Ã³wnej idei projektu)

### Implementacja serwisu file-sink

TODO

#### Symulacja bÅ‚Ä™dÃ³w w serwisie file-sink

Fragment `file-sink/index.js` odpowiadajÄ…cy za symulacjÄ™ bÅ‚Ä™dÃ³w
```javascript
 // Save the received event to a file (append mode)
 fs.appendFileSync('/data/events.log', JSON.stringify(req.body) + '\n');
 if (Math.random() < 0.5) {
   fs.appendFileSync('/data/events.log', 'error simulated\n');
   return res.status(500).send('Internal Server Error');
 }
 // Respond with a success message
 res.status(200).send('Event saved');
 ```

 ### Dead Letter Sink

 #### Definicja serwisu dead-letter-logger

 dead-letter-logger\config\dead-letter-logger.yaml

 ```yaml
 apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: dead-letter-logger
spec:
  template:
    metadata:
      annotations:
        # Tells Knative not to try pulling the image from Docker Hub
        "container.applinks.io/skipImagePull": "true"
    spec:
      containers:
        - image: dev.local/dead-letter-logger:latest
          volumeMounts:
            - name: data
              mountPath: /data
          ports:
            - containerPort: 8080
      volumes:
        - name: data
          emptyDir: {}
```

#### PodpiÄ™cie `dead-letter-logger` jako dead letter sink `bookstore-broker`

```
apiVersion: eventing.knative.dev/v1
kind: Broker
metadata:
  name: bookstore-broker
spec:
  delivery:
    deadLetterSink:
      ref:
        apiVersion: serving.knative.dev/v1
        kind: Service
        name: dead-letter-logger
    retry: 2
    backoffPolicy: exponential
    backoffDelay: PT1S
```

## **Konfiguracja i WdroÅ¼enie Systemu Telemetrii**

Sekcja szczegÃ³Å‚owo opisuje proces konfiguracji i wdroÅ¼enia kompleksowego systemu telemetrii w Å›rodowisku Kubernetes, wykorzystujÄ…cego Prometheus, GrafanÄ™ oraz OpenTelemetry Collector. Celem jest zbieranie metryk zarÃ³wno z komponentÃ³w systemu, jak i z aplikacyjnych punktÃ³w koÅ„cowych, w szczegÃ³lnoÅ›ci z serwisu Node.js.

#### **PrzeglÄ…d Architektury Monitorowania**

Zaimplementowany system monitorowania opiera siÄ™ na nastÄ™pujÄ…cych kluczowych komponentach:

* **Prometheus**: DziaÅ‚a jako centralna baza danych do przechowywania metryk, odpowiedzialna za ich zbieranie (scraping) oraz ocenÄ™ reguÅ‚ alertÃ³w.  
* **Grafana**: SÅ‚uÅ¼y do wizualizacji metryk zebranych przez Prometheusa, umoÅ¼liwiajÄ…c tworzenie dynamicznych pulpitÃ³w nawigacyjnych (dashboardÃ³w).  
* **OpenTelemetry Collector**: PeÅ‚ni rolÄ™ poÅ›rednika, ktÃ³ry zbiera metryki z aplikacji (w tym przypadku serwisu Node.js) w formacie Prometheus, a nastÄ™pnie przesyÅ‚a je do Prometheusa. Collector rÃ³wnieÅ¼ udostÄ™pnia swoje wÅ‚asne metryki stanu.

#### **Co jest monitorowane?**

System jest skonfigurowany do monitorowania dwÃ³ch gÅ‚Ã³wnych ÅºrÃ³deÅ‚ metryk:

1. **Sam OpenTelemetry Collector**: Prometheus aktywnie skrobie metryki zdrowia i wydajnoÅ›ci samego Collectora, zapewniajÄ…c wglÄ…d w jego dziaÅ‚anie.  
2. **Serwis node-server**: OpenTelemetry Collector skrobie metryki wystawiane przez serwis, a nastÄ™pnie przesyÅ‚a je do Prometheusa. Ten model odciÄ…Å¼a Prometheusa od bezpoÅ›redniego scrapowania aplikacji i pozwala na elastyczne przetwarzanie metryk przez Collector.

#### **Przewodnik po Konfiguracji Systemu**

PoniÅ¼sze kroki przedstawiajÄ… kompletny proces instalacji i konfiguracji opisanego systemu telemetrii.

1. **Instalacja Helm:**

   ```Bash  
   curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
   ```
2. **Dodanie repozytorium Helm dla Prometheus Community:**

   ```Bash  
   helm repo add prometheus-community [https://prometheus-community.github.io/helm-charts](https://prometheus-community.github.io/helm-charts)

    helm repo update
    ```

3. **Tworzenie przestrzeni nazw monitoring:**

    ```Bash 
    kubectl create namespace monitoring
    ```
     
4. **Instalacja kube-prometheus-stack przy uÅ¼yciu Helm:** Pakiet ten zawiera Prometheus, GrafanÄ™ i Alertmanager, a takÅ¼e inne komponenty Kubernetes do monitorowania. Grafana jest skonfigurowana do wystawiania na NodePort 30000 dla Å‚atwego dostÄ™pu.

   ```Bash  
   helm install prometheus prometheus-community/kube-prometheus-stack \
     --namespace monitoring \
     --set grafana.service.type=NodePort \
     --set grafana.service.nodePort=30000 \
     --set prometheus.prometheusSpec.maximumStartupDurationSeconds=60
     ```
5. **Weryfikacja instalacji Prometheus:** SprawdÅº, czy pody Prometheus sÄ… uruchomione.

   ```Bash  
   kubectl --namespace monitoring get pods -l "release=prometheus"
   ```
6. **Weryfikacja instalacji Grafany:** SprawdÅº, czy pody Grafana sÄ… uruchomione.

   ```Bash  
   kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana
   ```
7. **Pobranie hasÅ‚a administratora Grafany:**

   ```Bash  
   kubectl get secret -n monitoring prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 --decode
   ```

<br>
<img src='images\OTel_password_guide_1.png'>
<br>

wynik polecenia sÅ‚uÅ¼Ä…cego do pobrania i dekodowania hasÅ‚a administratora Grafany

8. **(Opcjonalnie) WdroÅ¼enie OpenTelemetry Collector:** PoniÅ¼sze komendy aplikujÄ… konfiguracjÄ™ Collectora, jego Deployment, Service, RBAC oraz ServiceMonitor. NaleÅ¼y upewniÄ‡ siÄ™, Å¼e pliki YAML sÄ… wczeÅ›niej poprawione (np. port 8888 dla wewnÄ™trznych metryk Collectora i prawidÅ‚owe uprawnienia RBAC).

   ```Bash  
   kubectl apply -f otel-collector/otel-collector-rbac.yaml  
   kubectl apply -f otel-collector/otel-collector-configmap.yaml  
   kubectl apply -f otel-collector/otel-collector-deployment.yaml  
   kubectl apply -f otel-collector/otel-collector-config.yaml  
   kubectl apply -f otel-collector/otel-collector-servicemonitor.yaml
   ```

Ten krok zakÅ‚ada, Å¼e pliki YAML znajdujÄ…ce siÄ™ w otel-collector/ zostaÅ‚y wczeÅ›niej zaktualizowane i zawierajÄ… prawidÅ‚owe konfiguracje, w tym poprawne porty i uprawnienia.

### **Wizualizacja i Weryfikacja Systemu Monitorowania**

PoniÅ¼sze zrzuty ekranu stanowiÄ… wizualne potwierdzenie poprawnego wdroÅ¼enia oraz funkcjonalnoÅ›ci systemu telemetrii. PrezentujÄ… kluczowe aspekty od dostÄ™pu do interfejsÃ³w, przez status celÃ³w skrobania, aÅ¼ po wizualizacjÄ™ zebranych metryk.

<br>
<img src='images\OTel_example_grafana_1.png'>
<br>

Ten pulpit Grafany, rÃ³wnieÅ¼ z Node Exporter, stosuje metodÄ™ USE (Utilization, Saturation, Errors) do zagregowanych metryk na poziomie caÅ‚ego klastra. Dostarcza szybkiego wglÄ…du w ogÃ³lny stan wydajnoÅ›ci i potencjalne problemy w klastrze  

<br>
<img src='images\OTel_example_grafana_2.png'>
<br>

Pulpit Node Exporter w Grafanie, ktÃ³ry wizualizuje metryki dotyczÄ…ce zasobÃ³w dla kaÅ¼dego pojedynczego wÄ™zÅ‚a w klastrze Kubernetes. UmoÅ¼liwia monitorowanie zuÅ¼ycia CPU, pamiÄ™ci i sieci dla poszczegÃ³lnych maszyn.

<br>
<img src='images\OTel_example_grafana_3.png'>
<br>

Pulpit nawigacyjny Grafany prezentujÄ…cy ogÃ³lny przeglÄ…d stanu i wydajnoÅ›ci serwera Prometheus. Wizualizuje kluczowe metryki dziaÅ‚ania samego systemu Prometheus.  

<br>
<img src='images\OTel_example_prometeus_1.png'>
<br>

Ten widok z interfejsu uÅ¼ytkownika Prometheus przedstawia listÄ™ wszystkich celÃ³w (targets) monitorowania. Wskazuje ich status (UP/DOWN) oraz szczegÃ³Å‚y skrobania, potwierdzajÄ…c, czy Prometheus skutecznie zbiera metryki ze skonfigurowanych ÅºrÃ³deÅ‚.

## **Opis DziaÅ‚ania Aplikacji**

W niniejszej sekcji przedstawiono wizualne potwierdzenie poprawnego uruchomienia komponentÃ³w frontendu i backendu aplikacji.  
**1\. DziaÅ‚anie Frontendu**
![frontend aplikacji](https://github.com/user-attachments/assets/af6bb047-549b-400c-9bc8-6074f7645661)

<br>
<img src='images\frontend_example_app_1.png'>
<br>

PowyÅ¼szy zrzut ekranu prezentuje poprawnie uruchomiony interfejs uÅ¼ytkownika (frontend) aplikacji.   

**2\. DziaÅ‚anie Backendu**
![Backend](https://github.com/user-attachments/assets/90a3824f-c8fe-4bed-b8e9-56b8fd36daaf)

<br>
<img src='images\backend_example_app_1.png'>
<br>

PowyÅ¼szy zrzut ekranu prezentuje poprawnie uruchomiony backendu aplikacji. 


W ramach naszego projektu dokonamy rozszerzenia aplikacji demonstracyjnej Bookstore, opartej na architekturze event-driven z wykorzystaniem Knative. GÅ‚Ã³wnym celem tej modyfikacji jest zaprezentowanie mechanizmÃ³w obsÅ‚ugi bÅ‚Ä™dÃ³w w systemie przesyÅ‚ania zdarzeÅ„, takich jak ponowne prÃ³by (retry) i obsÅ‚uga zdarzeÅ„ niedostarczalnych (dead-letter sink â€“ DLS). Dodamy teÅ¼Â observability w postaci Grafany poÅ‚Ä…czonej przez Prometheus z OpenTelemetry.

1. **Symulacja bÅ‚Ä™dÃ³w w usÅ‚udze Slack Sink:**

   * Wprowadzimy losowÄ… awaryjnoÅ›Ä‡ (np. zwracanie bÅ‚Ä™du HTTP 500\) w komponencie slack-sink, ktÃ³ry odpowiada za wysyÅ‚kÄ™ powiadomieÅ„ do Slacka.

   * Celem jest wymuszenie sytuacji, w ktÃ³rych zdarzenia nie sÄ… poprawnie przetwarzane.

2. **Dodanie mechanizmu Dead Letter Sink:**

   * Utworzymy osobny komponent (Knative Service), ktÃ³ry bÄ™dzie odbiorcÄ… zdarzeÅ„, ktÃ³re nie zostaÅ‚y pomyÅ›lnie dostarczone po okreÅ›lonej liczbie prÃ³b.

   * Zostanie on przypisany jako deadLetterSink w konfiguracji brokera (lub triggera).

3. **Konfiguracja polityki retry i backoff:**

   * Skonfigurujemy parametry retry w Knative Eventing (liczbÄ™ prÃ³b, politykÄ™ opÃ³ÅºnieÅ„).

   * UmoÅ¼liwi to demonstracjÄ™ automatycznego ponawiania dostarczania zdarzeÅ„ w przypadku niepowodzenia.

4. **ObserwowalnoÅ›Ä‡ i monitoring:**

   * WdroÅ¼ymy eksportery OpenTelemetry w kluczowych komponentach.

   * DziÄ™ki temu moÅ¼liwa bÄ™dzie analiza tras zdarzeÅ„, czasÃ³w przetwarzania, liczby prÃ³b oraz przypadkÃ³w przekierowania do DLS.


### **Wykorzystanie Kameleta do symulacji bÅ‚Ä™dÃ³w i obsÅ‚ugi przez Dead Letter Sink**

Zastosujemy Kamelet jako komponent poÅ›redniczÄ…cy, ktÃ³rego zadaniem bÄ™dzie celowe odrzucanie czÄ™Å›ci wiadomoÅ›ci. Celem jest wygenerowanie bÅ‚Ä™dÃ³w dostarczania, ktÃ³re trafiÄ… nastÄ™pnie do Dead Letter Sink (DLS), gdzie zostanÄ… przekazane do OpenTEL w celu zwizualizowania ich w Grafanie.

#### **Mechanizm dziaÅ‚ania:**

1. Kamelet zostanie zaimplementowany jako konsument wiadomoÅ›ci (sink), ktÃ³ry jako odpowiedÅº na co 5 wiadomoÅ›Ä‡ zwraca wyjÄ…tek..

2. W przypadku zwrÃ³cenia wyjÄ…tku przez Kameleta, Knative Eventing automatycznie podejmieÅ‚ prÃ³bÄ™ ponownego dostarczenia wiadomoÅ›ci zgodnie z politykÄ… *retry*.

3. Po przekroczeniu limitu prÃ³b, wiadomoÅ›Ä‡ zostanie przekierowana do wczeÅ›niej zdefiniowanego *Dead Letter Logger*, ktÃ³rym bÄ™dzie osobny Knative Service odpowiedzialny za logowanie bÅ‚Ä™dÃ³w. OdwoÅ‚anie do tego serwisu bÄ™dzie zdefiniowane jako *deadLetterSink* brokera *badword-broker (slack-sink/config/100-broker.yaml).*

4. DLS przekaÅ¼e informacje o nieudanych zdarzeniach do Grafany za poÅ›rednictwem zintegrowanego systemu monitoringu w standardzie Open Telemetry.

![](images/image3.png)


# Architektura RozwiÄ…zania

# Instalacja aplikacji

### Uruchomienie aplikacji

Przed uruchomieniem skryptu naleÅ¼y zainstalowaÄ‡ wszystkie wymagane komponenty opisane w rozdziale **â€Konfiguracja i WdroÅ¼enie Systemu Telemetriiâ€**. Dopiero po ich poprawnej instalacji moÅ¼na przystÄ…piÄ‡ do uruchomienia aplikacji wedÅ‚ug poniÅ¼szych krokÃ³w:

```bash  
./solution.sh
```  
Wykonujemy ewentualne polecenia wypisane przez skrypt.

# Uruchamianie demo

1. **Frontend**  
   Frontend aplikacji jest dostÄ™pny pod http://localhost:3000/

2. **Backend**  
   Prosty test backendu moÅ¼na zoabaczyÄ‡ pod http://localhost:8080/

3. **Dodawanie komentarza**  
   Po wejÅ›ciu na stronÄ™ frontendu uÅ¼ytkownik moÅ¼e dodaÄ‡ komentarz do ksiÄ…Å¼ki. Komentarz trafia do backendu, a nastÄ™pnie jako CloudEvent do brokera Knative. Broker przekazuje zdarzenie do usÅ‚ugi `file-sink` ktÃ³ra zapisuje wiadomoÅ›Ä‡ do pliku lokalnego. W przypadku bÅ‚Ä™dÃ³w (symulowanych w `file-sink`) zdarzenie trafia do `dead-letter-logger` gdzie rÃ³wnieÅ¼ jest zapisywane do pliku.

4. **Weryfikacja dziaÅ‚ania usÅ‚ug**  
   - Aby sprawdziÄ‡, jakie zdarzenia otrzymaÅ‚ `file-sink`, uÅ¼yj polecenia:
     ```bash
     kubectl exec -it <file-sink-pod-name> -- cat /data/events.log
     ```
   - Aby sprawdziÄ‡, jakie zdarzenia otrzymaÅ‚ `dead-letter-logger`, uÅ¼yj polecenia:
     ```bash
     kubectl exec -it <dead-letter-logger-pod-name> -- cat /data/events.log
     ```

# UÅ¼ycie AI

## Prompt:
```
RozwiÅ„ punkt 4. "Dodaj retry i dead-letter sink
Cel: pokazaÄ‡ jak Knative Eventing radzi sobie z bÅ‚Ä™dami."
kod modyfikowanego projektu znajduje siÄ™ https://github.com/knative/docs/tree/main/code-samples/eventing/bookstore-sample-app/solution
Dodatkowy opis modifikowanej aplikacji: Welcome to the solution directory of the Knative Bookstore tutorial. This directory contains the fully implemented version of the event-driven bookstore application using Knative. 

You can find the tutorial for this solution here.

Directory Structure
Here's an overview of the components in the solution:

bad-word-filter/: Knative Function for filtering out inappropriate content
db-service/: Database service for storing book reviews and comments
frontend/: User interface for the bookstore application built with Next.js
node-server/: Node.js server for handling backend operations
sentiment-analysis-app/: Knative Function for analyzing the sentiment of book reviews
sequence/: Knative Sequence setup for orchestrating workflows
slack-sink/: Integration with Slack for notifications with Apache Camel
Additional Files
setup.sh: Script for setting up the required services including installing Knative, frontend, and backend node-server
solution.sh: Script for installing everything, deploying the entire solution. It includes the setup script as well.
```
OdpowiedÅº:
Aby zilustrowaÄ‡ obsÅ‚ugÄ™ bÅ‚Ä™dÃ³w w Knative Eventing oraz wykorzystanie mechanizmu Dead Letter Sink (DLS) w aplikacji **bookstore-sample-app**, moÅ¼esz wprowadziÄ‡ nastÄ™pujÄ…ce modyfikacje:

---

### ğŸ”§ 1. Symulacja bÅ‚Ä™dÃ³w w usÅ‚udze Slack Sink

**Cel:** WymusiÄ‡ bÅ‚Ä™dy w dostarczaniu zdarzeÅ„ do usÅ‚ugi Slack Sink, aby przetestowaÄ‡ mechanizm ponownych prÃ³b i przekierowania do DLS.

**DziaÅ‚ania:**

* Zmodyfikuj kod usÅ‚ugi `slack-sink`, aby losowo zwracaÅ‚a bÅ‚Ä™dy HTTP 500.

  PrzykÅ‚ad w jÄ™zyku Go:

```go
  func handler(w http.ResponseWriter, r *http.Request) {
      if rand.Float32() < 0.5 {
          http.Error(w, "Simulated failure", http.StatusInternalServerError)
          return
      }
      // Normalne przetwarzanie
  }
```



* Zbuduj i zaktualizuj obraz kontenera `slack-sink` w klastrze Kubernetes.

---

### ğŸ“¦ 2. Konfiguracja Dead Letter Sink (DLS)

**Cel:** SkonfigurowaÄ‡ miejsce docelowe dla zdarzeÅ„, ktÃ³re nie zostaÅ‚y pomyÅ›lnie dostarczone po okreÅ›lonej liczbie prÃ³b.

**DziaÅ‚ania:**

* UtwÃ³rz prostÄ… usÅ‚ugÄ™ Knative, ktÃ³ra bÄ™dzie peÅ‚niÅ‚a rolÄ™ DLS, np. `dead-letter-logger`.([docs.triggermesh.io][1])

  PrzykÅ‚ad w jÄ™zyku Go:

```go
  func handler(w http.ResponseWriter, r *http.Request) {
      body, _ := ioutil.ReadAll(r.Body)
      log.Printf("Received dead letter: %s", string(body))
      w.WriteHeader(http.StatusOK)
  }
```



* Zdefiniuj usÅ‚ugÄ™ Knative:

```yaml
  apiVersion: serving.knative.dev/v1
  kind: Service
  metadata:
    name: dead-letter-logger
  spec:
    template:
      spec:
        containers:
          - image: <Å›cieÅ¼ka_do_obrazu_dead_letter_logger>
```



* Zaktualizuj konfiguracjÄ™ `Broker` lub `Trigger`, aby uwzglÄ™dniÄ‡ DLS:([docs.triggermesh.io][2])

```yaml
  apiVersion: eventing.knative.dev/v1
  kind: Broker
  metadata:
    name: bookstore-broker
  spec:
    delivery:
      deadLetterSink:
        ref:
          apiVersion: serving.knative.dev/v1
          kind: Service
          name: dead-letter-logger
      retry: 3
      backoffPolicy: exponential
      backoffDelay: PT1S
```



W powyÅ¼szej konfiguracji:

* `retry: 3` oznacza, Å¼e Knative podejmie 3 prÃ³by ponownego dostarczenia zdarzenia.

* `backoffPolicy: exponential` oraz `backoffDelay: PT1S` definiujÄ… strategiÄ™ opÃ³ÅºnieÅ„ miÄ™dzy prÃ³bami.([Knative][3], [julianfriedman.org][4])

---

### ğŸ” 3. Obserwacja i weryfikacja

**Cel:** MonitorowaÄ‡ dziaÅ‚anie mechanizmu DLS oraz ponownych prÃ³b dostarczania zdarzeÅ„.

**DziaÅ‚ania:**

* WysyÅ‚aj komentarze zawierajÄ…ce "bad words", aby wywoÅ‚aÄ‡ zdarzenia kierowane do `slack-sink`.

* Obserwuj logi usÅ‚ugi `dead-letter-logger`, aby potwierdziÄ‡ odbiÃ³r zdarzeÅ„ po nieudanych prÃ³bach dostarczenia.

* Monitoruj metryki i Å›lady (traces) za pomocÄ… narzÄ™dzi takich jak OpenTelemetry, Jaeger lub Prometheus, aby analizowaÄ‡ opÃ³Åºnienia, liczbÄ™ prÃ³b i inne parametry zwiÄ…zane z dostarczaniem zdarzeÅ„.

---

DziÄ™ki tym modyfikacjom moÅ¼esz skutecznie zilustrowaÄ‡ mechanizmy obsÅ‚ugi bÅ‚Ä™dÃ³w w Knative Eventing oraz wykorzystanie Dead Letter Sink w praktyce.

[1]: https://docs.triggermesh.io/1.24/guides/creatingadls/?utm_source=chatgpt.com "Creating a Bridge With a Dead Letter Sink (DLS) - TriggerMesh"
[2]: https://docs.triggermesh.io/1.27/guides/patterns/creatingadls/?utm_source=chatgpt.com "Creating a Bridge With a Dead Letter Sink (DLS) - TriggerMesh"
[3]: https://master--knative.netlify.app/v0.19-docs/eventing/event-delivery/?utm_source=chatgpt.com "Event delivery - Knative"
[4]: https://julianfriedman.org/docs/dev/eventing/event-delivery/?utm_source=chatgpt.com "Event delivery - Knative - Julian Friedman dot Org"

-------
## Prompt:
```
ZaporponowaÅ‚eÅ›: "Zaktualizuj konfiguracjÄ™ Broker lub Trigger, aby uwzglÄ™dniÄ‡ DLS:" Co jest lepiej zaktualizowaÄ‡ - konfiguracjÄ™ Broker czy Trigger? Czy jest jakaÅ› rÃ³Å¼nica?
```
Åšwietne pytanie â€” i tak, **jest rÃ³Å¼nica** miÄ™dzy ustawieniem Dead Letter Sink (DLS) na **Brokerze** a na **Triggerze**, i wybÃ³r zaleÅ¼y od tego, **co dokÅ‚adnie chcesz osiÄ…gnÄ…Ä‡**.

---

### ğŸ”¹ **DLS na poziomie Triggera (`spec.delivery.deadLetterSink`)**

* **Zalecane w wiÄ™kszoÅ›ci przypadkÃ³w**.
* DziaÅ‚a tylko dla konkretnego Triggera â€” czyli tylko wtedy, gdy to konkretny subskrybent nie moÅ¼e poprawnie przetworzyÄ‡ zdarzenia.
* Pozwala mieÄ‡ **rÃ³Å¼ne DLS-y dla rÃ³Å¼nych TriggerÃ³w**, co jest bardzo przydatne np. gdy masz rÃ³Å¼ne typy bÅ‚Ä™dÃ³w w rÃ³Å¼nych czÄ™Å›ciach systemu.
* Daje wiÄ™kszÄ… kontrolÄ™ i obserwowalnoÅ›Ä‡ nad tym, *kto konkretnie zawiÃ³dÅ‚*.

âœ… **Kiedy uÅ¼ywaÄ‡:**
Gdy chcesz Å›ledziÄ‡ bÅ‚Ä™dy konkretnego odbiorcy (np. Slacka), lub masz wiele triggerÃ³w i chcesz kaÅ¼demu przypisaÄ‡ osobnÄ… logikÄ™ obsÅ‚ugi bÅ‚Ä™dÃ³w.

---

### ğŸ”¸ **DLS na poziomie Brokera (`spec.config.delivery.deadLetterSink`)**

* DziaÅ‚a **globalnie** dla wszystkich TriggerÃ³w korzystajÄ…cych z tego Brokera.
* UÅ¼ywana jako â€domyÅ›lnaâ€ strategia bÅ‚Ä™dÃ³w, jeÅ›li konkretne Triggery jej nie nadpisujÄ….
* MoÅ¼e pomÃ³c, gdy chcesz mieÄ‡ **jedno centralne miejsce logowania bÅ‚Ä™dÃ³w** (np. wspÃ³lny temat w Kafka, CloudEvent logger, itp.).

âš ï¸ **Ograniczenie:**
Nie wiesz dokÅ‚adnie, ktÃ³ry Trigger/subskrybent zawiÃ³dÅ‚, jeÅ›li nie przechowujesz tej informacji w treÅ›ci zdarzenia.

âœ… **Kiedy uÅ¼ywaÄ‡:**
Gdy chcesz mieÄ‡ domyÅ›lne zabezpieczenie â€na wszelki wypadekâ€ albo gdy masz proste Å›rodowisko z jednym gÅ‚Ã³wnym celem logowania bÅ‚Ä™dÃ³w.

---

### ğŸ“Œ **Podsumowanie: co lepiej zaktualizowaÄ‡?**

W Twoim projekcie (gdzie testujesz *losowe bÅ‚Ä™dy tylko w jednej konkretnej usÅ‚udze* â€“ Slack sink), **lepiej ustawiÄ‡ DLS na poziomie Triggera**. UmoÅ¼liwia to precyzyjne testowanie retry i DLS tylko dla tego jednego przypadku, bez wpÅ‚ywu na resztÄ™ systemu.


Chcesz przykÅ‚ad konfiguracji DLS w Triggerze na podstawie Twojego projektu?

------

## prompt: nie zostaÅ‚ zapisany, coÅ› podobnego do "Napisz testowy serwis Knative ktÃ³ry bÄ™dzie odbieraÅ‚ wiadomoÅ›ci od node-server". OdpoweidÅº powstaÅ‚a iteracyjnie po paru promptach.

To create a simple Knative service and enable communication between your node server and this
test service, follow these steps:
1. Create a simple Knative Service (YAML example)
Create a file, e.g., test-service.yaml:
```
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
name: test-service
spec:
template:
spec:
containers:
- image: docker.io/library/nginx:alpine # or your own test image
ports:
- containerPort: 80
```
Apply it with:
kubectl apply -f test-service.yaml
2. Add communication from node server to test service
You need to create a Knative Trigger that sends events from the broker (used by your node server)
to the test-service. Example trigger (test-trigger.yaml):
```
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
name: test-service-trigger
spec:
broker: bookstore-broker
filter:
attributes:
type: test-event # or whatever event type you want to route
subscriber:
ref:
apiVersion: serving.knative.dev/v1
kind: Service
name: test-service
```
Apply it with:
kubectl apply -f test-trigger.yaml
3. Send an event from node server
In your node server code, send a CloudEvent with type: test-event to the broker endpoint. The
broker will route it to test-service via the trigger above.
Summary:
Deploy a Knative service (test-service).
Create a Trigger to route events from the broker to test-service.
Send events from your node server to the broker with the correct type.
Let me know if you want a sample Node.js code snippet for sending the event!
To send a message from the node server to the Knative Sequence, you can add an endpoint that
sends a CloudEvent of type new-review-comment to the broker (which will then be routed to the
Sequence).
Here is a sample Express route you can add to your index.js:
```
// ...existing code...
const fetch = require('node-fetch'); // Add at the top if not already present
app.post('/send-to-sequence', async (req, res) => {
 try {
 const brokerURI = process.env.K_SINK || 'http://bookstore-broker.knativeeventing.svc.cluster.local'; // Use env or default
 const reviewText = req.body.reviewText || "Test review from node-server";
 const event = {
 specversion: "1.0",
 type: "new-review-comment",
 source: "node-server",
 id: Date.now().toString(),
 datacontenttype: "application/json",
 data: {
 reviewText: reviewText
 }
 };
 const response = await fetch(brokerURI, {
 method: 'POST',
 headers: {
 'Content-Type': 'application/cloudevents+json',
 },
 body: JSON.stringify(event),
 });
 if (!response.ok) {
 return res.status(500).json({error: 'Failed to send event to sequence'});
 }
 res.status(200).json({success: true, message: 'Event sent to sequence'});
 } catch (error) {
 res.status(500).json({error: 'Internal server error'});
 }
});
// ...existing codeâ€¦
```
This will allow you to POST to /send-to-sequence with a JSON body like { "reviewText": "Hello
Sequence!" } and have the event routed through your Knative Sequence.
To create a service that receives these messages (CloudEvents from the Sequence) and saves them
to a file, you can use a simple Knative Service with a minimal HTTP server. Hereâ€™s how you can do
it:
1. Create a Dockerized Node.js Service
index.js:
```
const express = require('express');
const fs = require('fs');
const app = express();
const PORT = process.env.PORT || 8080;
app.use(express.json());
app.post('/', (req, res) => {
 // Save the received event to a file (append mode)
 fs.appendFileSync('/data/events.log', JSON.stringify(req.body) + '\n');
 res.status(200).send('Event saved');
});
app.listen(PORT, () => {
 console.log(`File sink service listening on port ${PORT}`);
});
```
dokckerfile:
```
FROM node:18-alpine
WORKDIR /app
COPY index.js .
RUN npm install express
VOLUME ["/data"]
CMD ["node", "index.js"]
```
2. Build and Push the Image
```
docker build -t <your-dockerhub-username>/file-sink:latest .
docker push <your-dockerhub-username>/file-sink:latest
```
3. Deploy as a Knative Service
file-sink.yaml:
```
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
 name: file-sink
spec:
 template:
 spec:
 containers:
 - image: <your-dockerhub-username>/file-sink:latest
 volumeMounts:
 - name: data
 mountPath: /data
 volumes:
 - name: data
 emptyDir: {}
```
Apply with:
kubectl apply -f file-sink.yaml
4. Route Events to the Service
Create a Trigger or set the Sequenceâ€™s reply to point to this service, e.g.:
reply:
 ref:
 apiVersion: serving.knative.dev/v1
 kind: Service
 name: file-sink
Or use a Trigger to route from the broker to file-sink.
Summary:
The service receives HTTP POSTs (CloudEvents), appends them to /data/events.log.
Deploy as a Knative Service.
Route events to it from your Sequence or Broker.
Let me know if you want a ready-to-use YAML or more details!

-----
## UÅ¼ycie AI do radzenia sobie z bÅ‚Ä™dami

W tym projekcie narzÄ™dzia AI byÅ‚y czÄ™sto wykorzystywane w ten sposÃ³b. Spisanie wszystkich takich promptÃ³w ma ograniczony sens wiÄ™c postanowiliÅ›my przedstawiÄ‡ tylko jeden, przykÅ‚adowy prompt:

### Prompt:
```
I've rebuilt my image:
eval $(minikube docker-env)
docker build -t file-sink:latest .
docker tag file-sink:latest dev.local/file-sink:latest


and I wanted to reapply the configuration so a new image gets pulled:
kn service apply file-sink --image=dev.local/file-sink --pull-policy=Never
but I got:

No changes to apply to service 'file-sink'
```

OdpowiedÅº:


The message:

```
No changes to apply to service 'file-sink'
```

means that `kn service apply` detected no difference between the existing service and the new one you're trying to apply â€” so it skips any update.

This happens even if you've rebuilt the image, because Knative identifies the image by its reference (`dev.local/file-sink`) â€” **not by its content**. Since you're using `--pull-policy=Never`, it expects the image to be locally available and doesn't try to fetch a newer version.

### âœ… Solutions

#### ğŸ” Option 1: Force an update by changing the image reference

Add a **dummy tag** (like a timestamp or version bump) to ensure `kn` detects a change:

```bash
NEW_TAG="dev.local/file-sink:$(date +%s)"
docker tag file-sink:latest $NEW_TAG
kn service apply file-sink --image=$NEW_TAG --pull-policy=Never
```

This tricks Knative into thinking it's a different image, even though it's actually the same one locally.

---

#### ğŸ”„ Option 2: Delete and recreate the service (not always ideal)

If you donâ€™t mind downtime or losing service state:

```bash
kn service delete file-sink
kn service create file-sink --image=dev.local/file-sink:latest --pull-policy=Never
```

---

#### ğŸ”„ Option 3: Use `kn service update` instead

Sometimes `kn service update` forces a new revision even when `apply` doesn't:

```bash
kn service update file-sink --image=dev.local/file-sink:latest --pull-policy=Never
```

This can trigger a rollout without needing to change the tag.

---

Let me know if you want to automate this tagging or update it directly in your build script.


---------------------------------------
---------------------------------------
---------------------------------------


# Podsumowanie i wnioski

Podczas realizacji projektu napotkaliÅ›my istotne trudnoÅ›ci zwiÄ…zane z konfiguracjÄ… oryginalnej aplikacji demonstracyjnej Knative Bookstore. GÅ‚Ã³wnym problemem byÅ‚ brak aktywnego rozwoju tej aplikacji, co skutkowaÅ‚o niekompatybilnoÅ›ciÄ… wersji, przestarzaÅ‚ymi zaleÅ¼noÅ›ciami i nieaktualnÄ… dokumentacjÄ…. 

Ze smutkiem wspominamy kaÅ¼dÄ… godzinÄ™ poÅ›wiÄ™conÄ… na prÃ³bÄ™ otworzenia oryginalnej aplikacji, zanim zorientowaliÅ›my siÄ™ Å¼e to nie jest optymalne podejÅ›cie, ale liczymy Å¼e kaÅ¼da z tych godzin dosadniej uÅ›wiadomiÅ‚a nam jak waÅ¼ne jest caÅ‚oÅ›ciowe i krytyczne spojrzenie na projekt.

Kluczowe okazaÅ‚o siÄ™ skupienie na rzeczywistej istocie projektu â€“ telemetri, demonstracji mechanizmÃ³w event-driven, oraz dodatkowo obsÅ‚ugi bÅ‚Ä™dÃ³w w Knative â€“ zamiast wiernego odtwarzania kaÅ¼dego elementu oryginalnej architektury. W przypadku problemÃ³w konfiguracyjnych uproÅ›ciliÅ›my rozwiÄ…zanie, zastÄ™pujÄ…c problematyczne serwisy wÅ‚asnymi, prostszymi komponentami. Takie podejÅ›cie pozwoliÅ‚o nam nie tylko ukoÅ„czyÄ‡ projekt, ale takÅ¼e lepiej zrozumieÄ‡ kluczowe mechanizmy Knative i praktyczne aspekty wdraÅ¼ania rozwiÄ…zaÅ„ serverless oraz event-driven w Kubernetes. 

UdaÅ‚o siÄ™ skutecznie wdroÅ¼yÄ‡ system observability z wykorzystaniem OpenTelemetry, Prometheusa i Grafany. ByÅ‚o to ksztaÅ‚cÄ…ce doÅ›wiadczenie, ktÃ³re pozwoliÅ‚o nam w praktyce poznaÄ‡, jak dziaÅ‚ajÄ… narzÄ™dzia do monitorowania i Å›ledzenia przepÅ‚ywu zdarzeÅ„ w architekturze event-driven. DziÄ™ki temu mogliÅ›my lepiej zrozumieÄ‡ zarÃ³wno techniczne aspekty wdroÅ¼enia, jak i korzyÅ›ci pÅ‚ynÄ…ce z monitorowania rozproszonych systemÃ³w.

# **PodziaÅ‚ zadaÅ„**

* modyfikacja aplikacji: symulacja bÅ‚Ä™dÃ³w w usÅ‚udze Slack Sink i obsÅ‚uga bÅ‚Ä™dÃ³w (2 os.)  
* itegracja aplikacji z OTel  
* integracja z GrafanÄ…
