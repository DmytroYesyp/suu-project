Knative \- OTel
==============

[GoogleDocs](https://docs.google.com/document/d/1zVsoGiIb50rPzTMCSIOD62AAp-FyuXdTZhBHDyCoWtY/edit?tab=t.0)


**Jan Chyczy≈Ñski, Kacper Kozak, Dmytro Yesyp, Bart≈Çomiej S≈Çupik**

# Wprowadzenie

Ten projekt demonstruje praktyczne zastosowanie Knative na przyk≈Çadzie zmodyfikowanej aplikacji Bookstore ‚Äì prostej ksiƒôgarni internetowej dzia≈ÇajƒÖcej w architekturze event-driven. Aplikacja zosta≈Ça rozszerzona o mechanizmy obs≈Çugi b≈Çƒôd√≥w, takie jak retry i dead letter sink, oraz zintegrowana z OpenTelemetry i GrafanƒÖ w celu monitorowania przep≈Çywu zdarze≈Ñ. Projekt ilustruje kluczowe cechy Knative, takie jak przetwarzanie zdarze≈Ñ, elastyczne skalowanie oraz niezawodna obs≈Çuga niepowodze≈Ñ, dajƒÖc jednocze≈õnie wglƒÖd w dzia≈Çanie systemu dziƒôki wizualizacji metryk i ≈õledzeniu zdarze≈Ñ w czasie rzeczywistym.

# Podstawy teoretyczne i opis stosu technologicznego

Knative to system, kt√≥ry pomaga deweloperom w zarzƒÖdzaniu i utrzymywaniu proces√≥w w Kubernetes. Jego celem jest uproszczenie, zautomatyzowanie i monitorowanie wdro≈ºe≈Ñ w Kubernetes, aby zespo≈Çy spƒôdza≈Çy mniej czasu na konserwacji, a wiƒôcej na tworzeniu aplikacji i realizacji projekt√≥w. Knative przejmuje powtarzalne i czasoch≈Çonne zadania, eliminujƒÖc wƒÖskie gard≈Ça i op√≥≈∫nienia.

Te za≈Ço≈ºenia realizowane sƒÖ za pomocƒÖ dw√≥ch funkcji. Pierwsza to **Knative Eventing**, kt√≥ra pozwala deweloperom definiowaƒá akcje wyzwalane przez okre≈õlone zdarzenia zachodzƒÖce w szerszym ≈õrodowisku. Druga to **Knative Serving**, kt√≥ra automatycznie zarzƒÖdza tworzeniem oraz skalowaniem us≈Çug w Kubernetes, w≈ÇƒÖcznie ze skalowaniem do zera. Obie te funkcje majƒÖ na celu uwolnienie zasob√≥w, kt√≥re zespo≈Çy normalnie musia≈Çyby przeznaczyƒá na zarzƒÖdzanie systemami. Dodatkowo przynoszƒÖ one oszczƒôdno≈õci finansowe, reagujƒÖc na zmieniajƒÖce siƒô warunki w czasie rzeczywistym, w≈ÇƒÖczajƒÖc w to ‚Äúskalowanie do zera‚Äù  ‚Äî firmy p≈ÇacƒÖ tylko za zasoby, kt√≥re faktycznie wykorzystujƒÖ, a nie za te, kt√≥re mog≈Çyby potencjalnie zu≈ºyƒá.

Kluczowa idea Knative polega na umo≈ºliwieniu zespo≈Çom wykorzystania potencja≈Çu bezserwerowego wdra≈ºania aplikacji. ‚ÄûServerless‚Äù odnosi siƒô do zarzƒÖdzania serwerami i maszynami wirtualnymi w chmurze, czƒôsto udostƒôpnianymi przez platformy takie jak AWS, Google Cloud czy Microsoft Azure. Serverless to doskona≈Çe rozwiƒÖzanie dla firm, kt√≥re chcƒÖ odej≈õƒá od kosztownego utrzymywania w≈Çasnych serwer√≥w i infrastruktury.

**OpenTelemetry** to otwarty standard oraz zbi√≥r narzƒôdzi, bibliotek i API, stworzony w celu zbierania danych telemetrycznych z oprogramowania. Jego g≈Ç√≥wnym celem jest standaryzacja sposobu instrumentowania aplikacji, umo≈ºliwiajƒÖc deweloperom gromadzenie danych o wykonywaniu kodu, niezale≈ºnie od u≈ºywanego jƒôzyka programowania czy frameworku, a tak≈ºe niezale≈ºnie od systemu monitorowania, kt√≥ry bƒôdzie te dane analizowa≈Ç i wizualizowa≈Ç (takich jak Grafana, Prometheus, Jaeger itp.).

OpenTelemetry koncentruje siƒô na trzech g≈Ç√≥wnych typach telemetrii: ≈õladach (traces), kt√≥re ≈õledzƒÖ drogƒô ≈ºƒÖdania przez rozproszony system; metrykach (metrics), kt√≥re mierzƒÖ wska≈∫niki wydajno≈õci (np. liczbƒô ≈ºƒÖda≈Ñ, czas odpowiedzi, wykorzystanie zasob√≥w); oraz logach (logs), kt√≥re rejestrujƒÖ zdarzenia w aplikacji. IntegrujƒÖc biblioteki OpenTelemetry ze swoim kodem, "instrumentujesz" go, aby automatycznie lub zgodnie z Twoimi wytycznymi generowa≈Ç te dane. Nastƒôpnie dane te mogƒÖ byƒá eksportowane (za po≈õrednictwem OpenTelemetry Collector lub bezpo≈õrednio) do r√≥≈ºnych system√≥w backendowych w celu przechowywania, analizy, wizualizacji i alertowania, co zapewnia g≈Çƒôbokie zrozumienie dzia≈Çania systemu, lokalizacjƒô problem√≥w i ich rozwiƒÖzywanie.

**G≈Ç√≥wne cechy Knative:**

* Automatyczne skalowanie w oparciu o obciƒÖ≈ºenie ruchem. Wprowdza skalowanie do zera, pozwalajƒÖce zmniejszyƒá u≈ºycie zasob√≥w.  
* Natywne wsparcie dla architektury Event-driven, kt√≥ra w samym Kubernetesie wymaga u≈ºycia zewnƒôtrznego narzƒôdzia takiego jak RabbitMQ czy Kafka.  
* ‚ÄúRevisions‚Äù \- knative tworzy snapshoty serwis√≥w i ich konfiguracji co u≈Çatwia operacje takie jak rollback i wersjonowanie.  
* Traffic splitting \- pozwala trasowaƒá ruch na wiele ‚Äúrevisions‚Äù w prosty spos√≥b wspierajƒÖc ‚ÄúCanary release‚Äù czy A/B testing.  
* U≈Çatwia development wprowadzajƒÖc CRD ‚ÄúService‚Äù, zastƒôpujƒÖcy Deploymenty/Statefulsety i obs≈ÇugujƒÖcy routing czy scalling co w czystym kubernetesie wymaga≈Çoby zdefiniowania i skonfigurowania dodatkowych zasob√≥w.  
* Wbudowane trasowanie \- automatyczne generowanie tras HTTP z mo≈ºliwo≈õciƒÖ dostosowania domen.

Knative posiada r√≥wnie≈º wbudowane mechanizmy obs≈Çugi b≈Çƒôd√≥w, kt√≥re zwiƒôkszajƒÖ niezawodno≈õƒá architektury event-driven. W przypadku gdy dostarczenie zdarzenia do jednej z us≈Çug zako≈Ñczy siƒô niepowodzeniem, mo≈ºliwe jest automatyczne ponawianie pr√≥b zgodnie z konfigurowalnƒÖ politykƒÖ retry. Je≈õli mimo pr√≥b dostarczenie siƒô nie powiedzie, zdarzenie mo≈ºe zostaƒá przekierowane do tzw. *Dead Letter Sink* ‚Äî specjalnego komponentu, kt√≥ry przechowuje lub loguje zdarzenia niedostarczone. Dziƒôki temu ≈ºadne dane nie zostajƒÖ utracone, a deweloperzy mogƒÖ ≈Çatwo analizowaƒá przyczyny niepowodze≈Ñ.

### Stos technologiczny

Projekt oparty jest na Kubernetes i wykorzystuje Knative do zarzƒÖdzania us≈Çugami i przetwarzania zdarze≈Ñ w architekturze event-driven. Backend aplikacji zbudowany jest w Node.js, interfejs u≈ºytkownika w Next.js, a dane przechowywane sƒÖ w PostgreSQL. Przetwarzanie komentarzy realizujƒÖ funkcje Knative wykorzystujƒÖce modele ML do analizy sentymentu i filtrowania tre≈õci. Do monitorowania systemu zastosowano OpenTelemetry oraz Grafanƒô, umo≈ºliwiajƒÖc wizualizacjƒô przep≈Çywu zdarze≈Ñ i metryk zwiƒÖzanych z obs≈ÇugƒÖ b≈Çƒôd√≥w.

# Koncepcja projektu

[Knative Bookstore Code Samples: GitHub Aplikacja Bookstore](https://github.com/knative/docs/tree/main/code-samples/eventing/bookstore-sample-app/solution)

Opis katalogu ‚Äûsolution‚Äù przyk≈Çadowej aplikacji Knative Bookstore ‚Äì w pe≈Çni zaimplementowanego, event-driven sklepu z ksiƒÖ≈ºkami opartego na Knative Eventing. Kod ≈∫r√≥d≈Çowy dostƒôpny jest tutaj:

#### **Struktura**

1. **bad-word-filter/**  
    Funkcja Knative filtrujƒÖca nieodpowiednie tre≈õci w komentarzach.

2. **db-service/**  
    Us≈Çuga bazodanowa przechowujƒÖca recenzje i komentarze do ksiƒÖ≈ºek.

3. **frontend/**  
    Interfejs u≈ºytkownika aplikacji Bookstore, zbudowany w Next.js.

4. **node-server/**  
    Serwer Node.js obs≈ÇugujƒÖcy zaplecze (backend) aplikacji.

5. **sentiment-analysis-app/**  
    Funkcja Knative analizujƒÖca sentyment recenzji ksiƒÖ≈ºek.

6. **sequence/**  
    Konfiguracja Knative Sequence do orkiestracji przep≈Çywu zdarze≈Ñ miƒôdzy komponentami.

7. **slack-sink/**  
    Integracja z Slack (Apache Camel) wysy≈ÇajƒÖca powiadomienia o nowych recenzjach.

<br>
<img src='images/image1.png'>
<br>

## Modyfikacja aplikacji Bookstore (Knative Eventing)

W ramach naszego projektu dokonamy rozszerzenia aplikacji demonstracyjnej Bookstore, opartej na architekturze event-driven z wykorzystaniem Knative. G≈Ç√≥wnym celem tej modyfikacji jest zaprezentowanie mechanizm√≥w obs≈Çugi b≈Çƒôd√≥w w systemie przesy≈Çania zdarze≈Ñ, takich jak ponowne pr√≥by (retry) i obs≈Çuga zdarze≈Ñ niedostarczalnych (dead-letter sink ‚Äì DLS). Dodamy te≈º¬†observability w postaci Grafany po≈ÇƒÖczonej przez Prometheus z OpenTelemetry.

1. **Symulacja b≈Çƒôd√≥w w us≈Çudze Slack Sink:**

   * Wprowadzimy losowƒÖ awaryjno≈õƒá (np. zwracanie b≈Çƒôdu HTTP 500\) w komponencie slack-sink, kt√≥ry odpowiada za wysy≈Çkƒô powiadomie≈Ñ do Slacka.

   * Celem jest wymuszenie sytuacji, w kt√≥rych zdarzenia nie sƒÖ poprawnie przetwarzane.

2. **Dodanie mechanizmu Dead Letter Sink:**

   * Utworzymy osobny komponent (Knative Service), kt√≥ry bƒôdzie odbiorcƒÖ zdarze≈Ñ, kt√≥re nie zosta≈Çy pomy≈õlnie dostarczone po okre≈õlonej liczbie pr√≥b.

   * Zostanie on przypisany jako deadLetterSink w konfiguracji brokera (lub triggera).

3. **Konfiguracja polityki retry i backoff:**

   * Skonfigurujemy parametry retry w Knative Eventing (liczbƒô pr√≥b, politykƒô op√≥≈∫nie≈Ñ).

   * Umo≈ºliwi to demonstracjƒô automatycznego ponawiania dostarczania zdarze≈Ñ w przypadku niepowodzenia.

4. **Obserwowalno≈õƒá i monitoring:**

   * Wdro≈ºymy eksportery OpenTelemetry w kluczowych komponentach.

   * Dziƒôki temu mo≈ºliwa bƒôdzie analiza tras zdarze≈Ñ, czas√≥w przetwarzania, liczby pr√≥b oraz przypadk√≥w przekierowania do DLS.


### **Wykorzystanie Kameleta do symulacji b≈Çƒôd√≥w i obs≈Çugi przez Dead Letter Sink**

Zastosujemy Kamelet jako komponent po≈õredniczƒÖcy, kt√≥rego zadaniem bƒôdzie celowe odrzucanie czƒô≈õci wiadomo≈õci. Celem jest wygenerowanie b≈Çƒôd√≥w dostarczania, kt√≥re trafiƒÖ nastƒôpnie do Dead Letter Sink (DLS), gdzie zostanƒÖ przekazane do OpenTEL w celu zwizualizowania ich w Grafanie.

#### **Mechanizm dzia≈Çania:**

1. Kamelet zostanie zaimplementowany jako konsument wiadomo≈õci (sink), kt√≥ry jako odpowied≈∫ na co 5 wiadomo≈õƒá zwraca wyjƒÖtek..

2. W przypadku zwr√≥cenia wyjƒÖtku przez Kameleta, Knative Eventing automatycznie podejmie≈Ç pr√≥bƒô ponownego dostarczenia wiadomo≈õci zgodnie z politykƒÖ *retry*.

3. Po przekroczeniu limitu pr√≥b, wiadomo≈õƒá zostanie przekierowana do wcze≈õniej zdefiniowanego *Dead Letter Logger*, kt√≥rym bƒôdzie osobny Knative Service odpowiedzialny za logowanie b≈Çƒôd√≥w. Odwo≈Çanie do tego serwisu bƒôdzie zdefiniowane jako *deadLetterSink* brokera *badword-broker (slack-sink/config/100-broker.yaml).*

4. DLS przeka≈ºe informacje o nieudanych zdarzeniach do Grafany za po≈õrednictwem zintegrowanego systemu monitoringu w standardzie Open Telemetry.

<br>
<img src='images/image3.png'>
<br>


# Architektura RozwiƒÖzania

### <br>
<img src='images/image2.png'>
<br>


Architektura Systemu Systemu Knative \- OTel (Zmodyfikowana)

## Implementacja modyfikacji aplikacji Bookstore

### Uproszczenie aplikacji

<br>
<img src='images\kamel.png'>
<br>

Z powodu przestarza≈Ço≈õci, niezgodno≈õci wersji i problem√≥w z konfiguracjƒÖ (a szczeg√≥lnie konfiguracjƒÖ Camel-K co obrazuje powy≈ºsza infografika) postanowiono usunaƒá nastƒôpujƒÖce serwisy:
* slack-sink (zastƒÖpiony przez file-sink)
* bad-word-filter (zbƒôdny dla g≈Ç√≥wnej idei projektu)
* sentiment-analysis-app (zbƒôdny dla g≈Ç√≥wnej idei projektu)

### Implementacja serwisu file-sink

TODO

#### Symulacja b≈Çƒôd√≥w w serwisie file-sink

Fragment `file-sink/index.js` odpowiadajƒÖcy za symulacjƒô b≈Çƒôd√≥w
```javascript
 // Save the received event to a file (append mode)
 fs.appendFileSync('/data/events.log', JSON.stringify(req.body) + '\n');
 if (Math.random() < 0.5) {
   fs.appendFileSync('/data/events.log', 'error simulated\n');
   return res.status(500).send('Internal Server Error');
 }
 // Respond with a success message
 res.status(200).send('Event saved');
 ```

 ### Dead Letter Sink

 #### Definicja serwisu dead-letter-logger

 dead-letter-logger\config\dead-letter-logger.yaml

 ```yaml
 apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: dead-letter-logger
spec:
  template:
    metadata:
      annotations:
        # Tells Knative not to try pulling the image from Docker Hub
        "container.applinks.io/skipImagePull": "true"
    spec:
      containers:
        - image: dev.local/dead-letter-logger:latest
          volumeMounts:
            - name: data
              mountPath: /data
          ports:
            - containerPort: 8080
      volumes:
        - name: data
          emptyDir: {}
```

#### Podpiƒôcie `dead-letter-logger` jako dead letter sink `bookstore-broker`

```
apiVersion: eventing.knative.dev/v1
kind: Broker
metadata:
  name: bookstore-broker
spec:
  delivery:
    deadLetterSink:
      ref:
        apiVersion: serving.knative.dev/v1
        kind: Service
        name: dead-letter-logger
    retry: 2
    backoffPolicy: exponential
    backoffDelay: PT1S
```

## **Konfiguracja i Wdro≈ºenie Systemu Telemetrii**

Sekcja szczeg√≥≈Çowo opisuje proces konfiguracji i wdro≈ºenia kompleksowego systemu telemetrii w ≈õrodowisku Kubernetes, wykorzystujƒÖcego Prometheus, Grafanƒô oraz OpenTelemetry Collector. Celem jest zbieranie metryk zar√≥wno z komponent√≥w systemu, jak i z aplikacyjnych punkt√≥w ko≈Ñcowych, w szczeg√≥lno≈õci z serwisu Node.js.

#### **PrzeglƒÖd Architektury Monitorowania**

Zaimplementowany system monitorowania opiera siƒô na nastƒôpujƒÖcych kluczowych komponentach:

* **Prometheus**: Dzia≈Ça jako centralna baza danych do przechowywania metryk, odpowiedzialna za ich zbieranie (scraping) oraz ocenƒô regu≈Ç alert√≥w.  
* **Grafana**: S≈Çu≈ºy do wizualizacji metryk zebranych przez Prometheusa, umo≈ºliwiajƒÖc tworzenie dynamicznych pulpit√≥w nawigacyjnych (dashboard√≥w).  
* **OpenTelemetry Collector**: Pe≈Çni rolƒô po≈õrednika, kt√≥ry zbiera metryki z aplikacji (w tym przypadku serwisu Node.js) w formacie Prometheus, a nastƒôpnie przesy≈Ça je do Prometheusa. Collector r√≥wnie≈º udostƒôpnia swoje w≈Çasne metryki stanu.

#### **Co jest monitorowane?**

System jest skonfigurowany do monitorowania dw√≥ch g≈Ç√≥wnych ≈∫r√≥de≈Ç metryk:

1. **Sam OpenTelemetry Collector**: Prometheus aktywnie skrobie metryki zdrowia i wydajno≈õci samego Collectora, zapewniajƒÖc wglƒÖd w jego dzia≈Çanie.  
2. **Serwis node-server**: OpenTelemetry Collector skrobie metryki wystawiane przez serwis, a nastƒôpnie przesy≈Ça je do Prometheusa. Ten model odciƒÖ≈ºa Prometheusa od bezpo≈õredniego scrapowania aplikacji i pozwala na elastyczne przetwarzanie metryk przez Collector.

#### **Przewodnik po Konfiguracji Systemu**

Poni≈ºsze kroki przedstawiajƒÖ kompletny proces instalacji i konfiguracji opisanego systemu telemetrii.

1. **Instalacja Helm:**

   ```Bash  
   curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
   ```
2. **Dodanie repozytorium Helm dla Prometheus Community:**

   ```Bash  
   helm repo add prometheus-community [https://prometheus-community.github.io/helm-charts](https://prometheus-community.github.io/helm-charts)

    helm repo update
    ```

3. **Tworzenie przestrzeni nazw monitoring:**

    ```Bash 
    kubectl create namespace monitoring
    ```
     
4. **Instalacja kube-prometheus-stack przy u≈ºyciu Helm:** Pakiet ten zawiera Prometheus, Grafanƒô i Alertmanager, a tak≈ºe inne komponenty Kubernetes do monitorowania. Grafana jest skonfigurowana do wystawiania na NodePort 30000 dla ≈Çatwego dostƒôpu.

   ```Bash  
   helm install prometheus prometheus-community/kube-prometheus-stack \
     --namespace monitoring \
     --set grafana.service.type=NodePort \
     --set grafana.service.nodePort=30000 \
     --set prometheus.prometheusSpec.maximumStartupDurationSeconds=60
     ```
5. **Weryfikacja instalacji Prometheus:** Sprawd≈∫, czy pody Prometheus sƒÖ uruchomione.

   ```Bash  
   kubectl --namespace monitoring get pods -l "release=prometheus"
   ```
6. **Weryfikacja instalacji Grafany:** Sprawd≈∫, czy pody Grafana sƒÖ uruchomione.

   ```Bash  
   kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana
   ```
7. **Pobranie has≈Ça administratora Grafany:**

   ```Bash  
   kubectl get secret -n monitoring prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 --decode
   ```

<br>
<img src='images\OTel_password_guide_1.png'>
<br>

wynik polecenia s≈Çu≈ºƒÖcego do pobrania i dekodowania has≈Ça administratora Grafany

8. **(Opcjonalnie) Wdro≈ºenie OpenTelemetry Collector:** Poni≈ºsze komendy aplikujƒÖ konfiguracjƒô Collectora, jego Deployment, Service, RBAC oraz ServiceMonitor. Nale≈ºy upewniƒá siƒô, ≈ºe pliki YAML sƒÖ wcze≈õniej poprawione (np. port 8888 dla wewnƒôtrznych metryk Collectora i prawid≈Çowe uprawnienia RBAC).

   ```Bash  
   kubectl apply -f otel-collector/otel-collector-rbac.yaml  
   kubectl apply -f otel-collector/otel-collector-configmap.yaml  
   kubectl apply -f otel-collector/otel-collector-deployment.yaml  
   kubectl apply -f otel-collector/otel-collector-config.yaml  
   kubectl apply -f otel-collector/otel-collector-servicemonitor.yaml
   ```

Ten krok zak≈Çada, ≈ºe pliki YAML znajdujƒÖce siƒô w otel-collector/ zosta≈Çy wcze≈õniej zaktualizowane i zawierajƒÖ prawid≈Çowe konfiguracje, w tym poprawne porty i uprawnienia.

### **Wizualizacja i Weryfikacja Systemu Monitorowania**

Poni≈ºsze zrzuty ekranu stanowiƒÖ wizualne potwierdzenie poprawnego wdro≈ºenia oraz funkcjonalno≈õci systemu telemetrii. PrezentujƒÖ kluczowe aspekty od dostƒôpu do interfejs√≥w, przez status cel√≥w skrobania, a≈º po wizualizacjƒô zebranych metryk.

<br>
<img src='images\OTel_example_grafana_1.png'>
<br>

Ten pulpit Grafany, r√≥wnie≈º z Node Exporter, stosuje metodƒô USE (Utilization, Saturation, Errors) do zagregowanych metryk na poziomie ca≈Çego klastra. Dostarcza szybkiego wglƒÖdu w og√≥lny stan wydajno≈õci i potencjalne problemy w klastrze  

<br>
<img src='images\OTel_example_grafana_2.png'>
<br>

Pulpit Node Exporter w Grafanie, kt√≥ry wizualizuje metryki dotyczƒÖce zasob√≥w dla ka≈ºdego pojedynczego wƒôz≈Ça w klastrze Kubernetes. Umo≈ºliwia monitorowanie zu≈ºycia CPU, pamiƒôci i sieci dla poszczeg√≥lnych maszyn.

<br>
<img src='images\OTel_example_grafana_3.png'>
<br>

Pulpit nawigacyjny Grafany prezentujƒÖcy og√≥lny przeglƒÖd stanu i wydajno≈õci serwera Prometheus. Wizualizuje kluczowe metryki dzia≈Çania samego systemu Prometheus.  

<br>
<img src='images\OTel_example_prometeus_1.png'>
<br>

Ten widok z interfejsu u≈ºytkownika Prometheus przedstawia listƒô wszystkich cel√≥w (targets) monitorowania. Wskazuje ich status (UP/DOWN) oraz szczeg√≥≈Çy skrobania, potwierdzajƒÖc, czy Prometheus skutecznie zbiera metryki ze skonfigurowanych ≈∫r√≥de≈Ç.

Metryki node servera w grafanie:
<br>
<img src='images\OTel_grafana_node-server_visualtisation_1.png'>
<br>

OTel-collector console:
<br>
<img src='images\OTel_otel-collector_console_1.png'>
<br>




## Wdro≈ºenie Systemu Trasowania (Tracingu) z U≈ºyciem Jaeger

  W celu uzyskania g≈Çƒôbszego wglƒÖdu w dzia≈Çanie poszczeg√≥lnych ≈ºƒÖda≈Ñ i operacji w systemie, wdro≈ºono r√≥wnie≈º system trasowania rozproszonego oparty o Jaeger. Umo≈ºliwia to ≈õledzenie przep≈Çywu ≈ºƒÖda≈Ñ przez r√≥≈ºne komponenty aplikacji, identyfikacjƒô wƒÖskich garde≈Ç oraz u≈Çatwia diagnozowanie problem√≥w.

### Architektura Trasowania

System trasowania zosta≈Ç zintegrowany z istniejƒÖcƒÖ architekturƒÖ monitorowania:

* Aplikacje (`node-server` i `file-sink`): Ka≈ºdy z tych serwis√≥w zosta≈Ç zinstrumentowany przy u≈ºyciu bibliotek OpenTelemetry. GenerujƒÖ one dane trasowania (tzw. spany) dla przychodzƒÖcych i wychodzƒÖcych ≈ºƒÖda≈Ñ.

* OpenTelemetry Collector: Dzia≈Ça jako centralny agent, kt√≥ry odbiera dane trasowania z obu serwis√≥w. Po ich przetworzeniu, kolektor przesy≈Ça je bezpo≈õrednio do backendu Jaeger.

* Jaeger: S≈Çu≈ºy jako system do przechowywania, analizy i wizualizacji zebranych tras. Udostƒôpnia interfejs u≈ºytkownika, kt√≥ry pozwala na szczeg√≥≈Çowe przeglƒÖdanie poszczeg√≥lnych ≈õlad√≥w.

### Konfiguracja i Implementacja

Implementacja trasowania objƒô≈Ça dwa kluczowe serwisy: `node-server` oraz `file-sink`. Aby w≈ÇƒÖczyƒá generowanie tras, dla ka≈ºdego z nich stworzono dedykowany plik konfiguracyjny JavaScript, kt√≥ry jest ≈Çadowany przy starcie aplikacji:

1. `tracing.js`: Odpowiedzialny za instrumentacjƒô serwisu node-server.

2. `file-sink-tracing.js`: Odpowiedzialny za instrumentacjƒô serwisu `file-sink` (uruchamianego przez `index.js`).

Pliki te inicjujƒÖ OpenTelemetry SDK, konfigurujƒÖ eksporter OTLP do wysy≈Çania danych do kolektora oraz automatycznie instrumentujƒÖ popularne biblioteki (takie jak Express.js czy klienty HTTP), aby minimalizowaƒá potrzebƒô rƒôcznych zmian w kodzie aplikacji.

Weryfikacja i Wizualizacja Tras
Poni≈ºsze zrzuty ekranu z interfejsu u≈ºytkownika Jaeger potwierdzajƒÖ, ≈ºe dane trasowania sƒÖ poprawnie zbierane i przesy≈Çane dla obu monitorowanych serwis√≥w.

<br>
<img src='images\file-sink-service_jaeger_traces_1.png'>
<br>

<br>
<img src='images\node-server_jaeger_traces_1.png'>
<br>

## **Opis Dzia≈Çania Aplikacji**

W niniejszej sekcji przedstawiono wizualne potwierdzenie poprawnego uruchomienia komponent√≥w frontendu i backendu aplikacji.  
**1\. Dzia≈Çanie Frontendu**
![frontend aplikacji](https://github.com/user-attachments/assets/af6bb047-549b-400c-9bc8-6074f7645661)

<br>
<img src='images\frontend_example_app_1.png'>
<br>

Powy≈ºszy zrzut ekranu prezentuje poprawnie uruchomiony interfejs u≈ºytkownika (frontend) aplikacji.   

**2\. Dzia≈Çanie Backendu**
![Backend](https://github.com/user-attachments/assets/90a3824f-c8fe-4bed-b8e9-56b8fd36daaf)

<br>
<img src='images\backend_example_app_1.png'>
<br>

Powy≈ºszy zrzut ekranu prezentuje poprawnie uruchomiony backendu aplikacji. 


W ramach naszego projektu dokonamy rozszerzenia aplikacji demonstracyjnej Bookstore, opartej na architekturze event-driven z wykorzystaniem Knative. G≈Ç√≥wnym celem tej modyfikacji jest zaprezentowanie mechanizm√≥w obs≈Çugi b≈Çƒôd√≥w w systemie przesy≈Çania zdarze≈Ñ, takich jak ponowne pr√≥by (retry) i obs≈Çuga zdarze≈Ñ niedostarczalnych (dead-letter sink ‚Äì DLS). Dodamy te≈º¬†observability w postaci Grafany po≈ÇƒÖczonej przez Prometheus z OpenTelemetry.

1. **Symulacja b≈Çƒôd√≥w w us≈Çudze Slack Sink:**

   * Wprowadzimy losowƒÖ awaryjno≈õƒá (np. zwracanie b≈Çƒôdu HTTP 500\) w komponencie slack-sink, kt√≥ry odpowiada za wysy≈Çkƒô powiadomie≈Ñ do Slacka.

   * Celem jest wymuszenie sytuacji, w kt√≥rych zdarzenia nie sƒÖ poprawnie przetwarzane.

2. **Dodanie mechanizmu Dead Letter Sink:**

   * Utworzymy osobny komponent (Knative Service), kt√≥ry bƒôdzie odbiorcƒÖ zdarze≈Ñ, kt√≥re nie zosta≈Çy pomy≈õlnie dostarczone po okre≈õlonej liczbie pr√≥b.

   * Zostanie on przypisany jako deadLetterSink w konfiguracji brokera (lub triggera).

3. **Konfiguracja polityki retry i backoff:**

   * Skonfigurujemy parametry retry w Knative Eventing (liczbƒô pr√≥b, politykƒô op√≥≈∫nie≈Ñ).

   * Umo≈ºliwi to demonstracjƒô automatycznego ponawiania dostarczania zdarze≈Ñ w przypadku niepowodzenia.

4. **Obserwowalno≈õƒá i monitoring:**

   * Wdro≈ºymy eksportery OpenTelemetry w kluczowych komponentach.

   * Dziƒôki temu mo≈ºliwa bƒôdzie analiza tras zdarze≈Ñ, czas√≥w przetwarzania, liczby pr√≥b oraz przypadk√≥w przekierowania do DLS.


### **Wykorzystanie Kameleta do symulacji b≈Çƒôd√≥w i obs≈Çugi przez Dead Letter Sink**

Zastosujemy Kamelet jako komponent po≈õredniczƒÖcy, kt√≥rego zadaniem bƒôdzie celowe odrzucanie czƒô≈õci wiadomo≈õci. Celem jest wygenerowanie b≈Çƒôd√≥w dostarczania, kt√≥re trafiƒÖ nastƒôpnie do Dead Letter Sink (DLS), gdzie zostanƒÖ przekazane do OpenTEL w celu zwizualizowania ich w Grafanie.

#### **Mechanizm dzia≈Çania:**

1. Kamelet zostanie zaimplementowany jako konsument wiadomo≈õci (sink), kt√≥ry jako odpowied≈∫ na co 5 wiadomo≈õƒá zwraca wyjƒÖtek..

2. W przypadku zwr√≥cenia wyjƒÖtku przez Kameleta, Knative Eventing automatycznie podejmie≈Ç pr√≥bƒô ponownego dostarczenia wiadomo≈õci zgodnie z politykƒÖ *retry*.

3. Po przekroczeniu limitu pr√≥b, wiadomo≈õƒá zostanie przekierowana do wcze≈õniej zdefiniowanego *Dead Letter Logger*, kt√≥rym bƒôdzie osobny Knative Service odpowiedzialny za logowanie b≈Çƒôd√≥w. Odwo≈Çanie do tego serwisu bƒôdzie zdefiniowane jako *deadLetterSink* brokera *badword-broker (slack-sink/config/100-broker.yaml).*

4. DLS przeka≈ºe informacje o nieudanych zdarzeniach do Grafany za po≈õrednictwem zintegrowanego systemu monitoringu w standardzie Open Telemetry.

![](images/image3.png)


# Architektura RozwiƒÖzania

# Instalacja aplikacji

### Uruchomienie aplikacji

Przed uruchomieniem skryptu nale≈ºy zainstalowaƒá wszystkie wymagane komponenty opisane w rozdziale **‚ÄûKonfiguracja i Wdro≈ºenie Systemu Telemetrii‚Äù**. Dopiero po ich poprawnej instalacji mo≈ºna przystƒÖpiƒá do uruchomienia aplikacji wed≈Çug poni≈ºszych krok√≥w:

```bash  
./solution.sh
```  
Wykonujemy ewentualne polecenia wypisane przez skrypt.

# Uruchamianie demo

1. **Frontend**  
   Frontend aplikacji jest dostƒôpny pod http://localhost:3000/

2. **Backend**  
   Prosty test backendu mo≈ºna zoabaczyƒá pod http://localhost:8080/

3. **Dodawanie komentarza**  
   Po wej≈õciu na stronƒô frontendu u≈ºytkownik mo≈ºe dodaƒá komentarz do ksiƒÖ≈ºki. Komentarz trafia do backendu, a nastƒôpnie jako CloudEvent do brokera Knative. Broker przekazuje zdarzenie do us≈Çugi `file-sink` kt√≥ra zapisuje wiadomo≈õƒá do pliku lokalnego. W przypadku b≈Çƒôd√≥w (symulowanych w `file-sink`) zdarzenie trafia do `dead-letter-logger` gdzie r√≥wnie≈º jest zapisywane do pliku.

4. **Weryfikacja dzia≈Çania us≈Çug**  
   - Aby sprawdziƒá, jakie zdarzenia otrzyma≈Ç `file-sink`, u≈ºyj polecenia:
     ```bash
     kubectl exec -it <file-sink-pod-name> -- cat /data/events.log
     ```
   - Aby sprawdziƒá, jakie zdarzenia otrzyma≈Ç `dead-letter-logger`, u≈ºyj polecenia:
     ```bash
     kubectl exec -it <dead-letter-logger-pod-name> -- cat /data/events.log
     ```

# U≈ºycie AI

## Prompt:
```
Rozwi≈Ñ punkt 4. "Dodaj retry i dead-letter sink
Cel: pokazaƒá jak Knative Eventing radzi sobie z b≈Çƒôdami."
kod modyfikowanego projektu znajduje siƒô https://github.com/knative/docs/tree/main/code-samples/eventing/bookstore-sample-app/solution
Dodatkowy opis modifikowanej aplikacji: Welcome to the solution directory of the Knative Bookstore tutorial. This directory contains the fully implemented version of the event-driven bookstore application using Knative. 

You can find the tutorial for this solution here.

Directory Structure
Here's an overview of the components in the solution:

bad-word-filter/: Knative Function for filtering out inappropriate content
db-service/: Database service for storing book reviews and comments
frontend/: User interface for the bookstore application built with Next.js
node-server/: Node.js server for handling backend operations
sentiment-analysis-app/: Knative Function for analyzing the sentiment of book reviews
sequence/: Knative Sequence setup for orchestrating workflows
slack-sink/: Integration with Slack for notifications with Apache Camel
Additional Files
setup.sh: Script for setting up the required services including installing Knative, frontend, and backend node-server
solution.sh: Script for installing everything, deploying the entire solution. It includes the setup script as well.
```
Odpowied≈∫:
Aby zilustrowaƒá obs≈Çugƒô b≈Çƒôd√≥w w Knative Eventing oraz wykorzystanie mechanizmu Dead Letter Sink (DLS) w aplikacji **bookstore-sample-app**, mo≈ºesz wprowadziƒá nastƒôpujƒÖce modyfikacje:

---

### üîß 1. Symulacja b≈Çƒôd√≥w w us≈Çudze Slack Sink

**Cel:** Wymusiƒá b≈Çƒôdy w dostarczaniu zdarze≈Ñ do us≈Çugi Slack Sink, aby przetestowaƒá mechanizm ponownych pr√≥b i przekierowania do DLS.

**Dzia≈Çania:**

* Zmodyfikuj kod us≈Çugi `slack-sink`, aby losowo zwraca≈Ça b≈Çƒôdy HTTP 500.

  Przyk≈Çad w jƒôzyku Go:

```go
  func handler(w http.ResponseWriter, r *http.Request) {
      if rand.Float32() < 0.5 {
          http.Error(w, "Simulated failure", http.StatusInternalServerError)
          return
      }
      // Normalne przetwarzanie
  }
```



* Zbuduj i zaktualizuj obraz kontenera `slack-sink` w klastrze Kubernetes.

---

### üì¶ 2. Konfiguracja Dead Letter Sink (DLS)

**Cel:** Skonfigurowaƒá miejsce docelowe dla zdarze≈Ñ, kt√≥re nie zosta≈Çy pomy≈õlnie dostarczone po okre≈õlonej liczbie pr√≥b.

**Dzia≈Çania:**

* Utw√≥rz prostƒÖ us≈Çugƒô Knative, kt√≥ra bƒôdzie pe≈Çni≈Ça rolƒô DLS, np. `dead-letter-logger`.([docs.triggermesh.io][1])

  Przyk≈Çad w jƒôzyku Go:

```go
  func handler(w http.ResponseWriter, r *http.Request) {
      body, _ := ioutil.ReadAll(r.Body)
      log.Printf("Received dead letter: %s", string(body))
      w.WriteHeader(http.StatusOK)
  }
```



* Zdefiniuj us≈Çugƒô Knative:

```yaml
  apiVersion: serving.knative.dev/v1
  kind: Service
  metadata:
    name: dead-letter-logger
  spec:
    template:
      spec:
        containers:
          - image: <≈õcie≈ºka_do_obrazu_dead_letter_logger>
```



* Zaktualizuj konfiguracjƒô `Broker` lub `Trigger`, aby uwzglƒôdniƒá DLS:([docs.triggermesh.io][2])

```yaml
  apiVersion: eventing.knative.dev/v1
  kind: Broker
  metadata:
    name: bookstore-broker
  spec:
    delivery:
      deadLetterSink:
        ref:
          apiVersion: serving.knative.dev/v1
          kind: Service
          name: dead-letter-logger
      retry: 3
      backoffPolicy: exponential
      backoffDelay: PT1S
```



W powy≈ºszej konfiguracji:

* `retry: 3` oznacza, ≈ºe Knative podejmie 3 pr√≥by ponownego dostarczenia zdarzenia.

* `backoffPolicy: exponential` oraz `backoffDelay: PT1S` definiujƒÖ strategiƒô op√≥≈∫nie≈Ñ miƒôdzy pr√≥bami.([Knative][3], [julianfriedman.org][4])

---

### üîç 3. Obserwacja i weryfikacja

**Cel:** Monitorowaƒá dzia≈Çanie mechanizmu DLS oraz ponownych pr√≥b dostarczania zdarze≈Ñ.

**Dzia≈Çania:**

* Wysy≈Çaj komentarze zawierajƒÖce "bad words", aby wywo≈Çaƒá zdarzenia kierowane do `slack-sink`.

* Obserwuj logi us≈Çugi `dead-letter-logger`, aby potwierdziƒá odbi√≥r zdarze≈Ñ po nieudanych pr√≥bach dostarczenia.

* Monitoruj metryki i ≈õlady (traces) za pomocƒÖ narzƒôdzi takich jak OpenTelemetry, Jaeger lub Prometheus, aby analizowaƒá op√≥≈∫nienia, liczbƒô pr√≥b i inne parametry zwiƒÖzane z dostarczaniem zdarze≈Ñ.

---

Dziƒôki tym modyfikacjom mo≈ºesz skutecznie zilustrowaƒá mechanizmy obs≈Çugi b≈Çƒôd√≥w w Knative Eventing oraz wykorzystanie Dead Letter Sink w praktyce.

[1]: https://docs.triggermesh.io/1.24/guides/creatingadls/?utm_source=chatgpt.com "Creating a Bridge With a Dead Letter Sink (DLS) - TriggerMesh"
[2]: https://docs.triggermesh.io/1.27/guides/patterns/creatingadls/?utm_source=chatgpt.com "Creating a Bridge With a Dead Letter Sink (DLS) - TriggerMesh"
[3]: https://master--knative.netlify.app/v0.19-docs/eventing/event-delivery/?utm_source=chatgpt.com "Event delivery - Knative"
[4]: https://julianfriedman.org/docs/dev/eventing/event-delivery/?utm_source=chatgpt.com "Event delivery - Knative - Julian Friedman dot Org"

-------
## Prompt:
```
Zaporponowa≈Çe≈õ: "Zaktualizuj konfiguracjƒô Broker lub Trigger, aby uwzglƒôdniƒá DLS:" Co jest lepiej zaktualizowaƒá - konfiguracjƒô Broker czy Trigger? Czy jest jaka≈õ r√≥≈ºnica?
```
≈öwietne pytanie ‚Äî i tak, **jest r√≥≈ºnica** miƒôdzy ustawieniem Dead Letter Sink (DLS) na **Brokerze** a na **Triggerze**, i wyb√≥r zale≈ºy od tego, **co dok≈Çadnie chcesz osiƒÖgnƒÖƒá**.

---

### üîπ **DLS na poziomie Triggera (`spec.delivery.deadLetterSink`)**

* **Zalecane w wiƒôkszo≈õci przypadk√≥w**.
* Dzia≈Ça tylko dla konkretnego Triggera ‚Äî czyli tylko wtedy, gdy to konkretny subskrybent nie mo≈ºe poprawnie przetworzyƒá zdarzenia.
* Pozwala mieƒá **r√≥≈ºne DLS-y dla r√≥≈ºnych Trigger√≥w**, co jest bardzo przydatne np. gdy masz r√≥≈ºne typy b≈Çƒôd√≥w w r√≥≈ºnych czƒô≈õciach systemu.
* Daje wiƒôkszƒÖ kontrolƒô i obserwowalno≈õƒá nad tym, *kto konkretnie zawi√≥d≈Ç*.

‚úÖ **Kiedy u≈ºywaƒá:**
Gdy chcesz ≈õledziƒá b≈Çƒôdy konkretnego odbiorcy (np. Slacka), lub masz wiele trigger√≥w i chcesz ka≈ºdemu przypisaƒá osobnƒÖ logikƒô obs≈Çugi b≈Çƒôd√≥w.

---

### üî∏ **DLS na poziomie Brokera (`spec.config.delivery.deadLetterSink`)**

* Dzia≈Ça **globalnie** dla wszystkich Trigger√≥w korzystajƒÖcych z tego Brokera.
* U≈ºywana jako ‚Äûdomy≈õlna‚Äù strategia b≈Çƒôd√≥w, je≈õli konkretne Triggery jej nie nadpisujƒÖ.
* Mo≈ºe pom√≥c, gdy chcesz mieƒá **jedno centralne miejsce logowania b≈Çƒôd√≥w** (np. wsp√≥lny temat w Kafka, CloudEvent logger, itp.).

‚ö†Ô∏è **Ograniczenie:**
Nie wiesz dok≈Çadnie, kt√≥ry Trigger/subskrybent zawi√≥d≈Ç, je≈õli nie przechowujesz tej informacji w tre≈õci zdarzenia.

‚úÖ **Kiedy u≈ºywaƒá:**
Gdy chcesz mieƒá domy≈õlne zabezpieczenie ‚Äûna wszelki wypadek‚Äù albo gdy masz proste ≈õrodowisko z jednym g≈Ç√≥wnym celem logowania b≈Çƒôd√≥w.

---

### üìå **Podsumowanie: co lepiej zaktualizowaƒá?**

W Twoim projekcie (gdzie testujesz *losowe b≈Çƒôdy tylko w jednej konkretnej us≈Çudze* ‚Äì Slack sink), **lepiej ustawiƒá DLS na poziomie Triggera**. Umo≈ºliwia to precyzyjne testowanie retry i DLS tylko dla tego jednego przypadku, bez wp≈Çywu na resztƒô systemu.


Chcesz przyk≈Çad konfiguracji DLS w Triggerze na podstawie Twojego projektu?

------

## prompt: nie zosta≈Ç zapisany, co≈õ podobnego do "Napisz testowy serwis Knative kt√≥ry bƒôdzie odbiera≈Ç wiadomo≈õci od node-server". Odpoweid≈∫ powsta≈Ça iteracyjnie po paru promptach.

To create a simple Knative service and enable communication between your node server and this
test service, follow these steps:
1. Create a simple Knative Service (YAML example)
Create a file, e.g., test-service.yaml:
```
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
name: test-service
spec:
template:
spec:
containers:
- image: docker.io/library/nginx:alpine # or your own test image
ports:
- containerPort: 80
```
Apply it with:
kubectl apply -f test-service.yaml
2. Add communication from node server to test service
You need to create a Knative Trigger that sends events from the broker (used by your node server)
to the test-service. Example trigger (test-trigger.yaml):
```
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
name: test-service-trigger
spec:
broker: bookstore-broker
filter:
attributes:
type: test-event # or whatever event type you want to route
subscriber:
ref:
apiVersion: serving.knative.dev/v1
kind: Service
name: test-service
```
Apply it with:
kubectl apply -f test-trigger.yaml
3. Send an event from node server
In your node server code, send a CloudEvent with type: test-event to the broker endpoint. The
broker will route it to test-service via the trigger above.
Summary:
Deploy a Knative service (test-service).
Create a Trigger to route events from the broker to test-service.
Send events from your node server to the broker with the correct type.
Let me know if you want a sample Node.js code snippet for sending the event!
To send a message from the node server to the Knative Sequence, you can add an endpoint that
sends a CloudEvent of type new-review-comment to the broker (which will then be routed to the
Sequence).
Here is a sample Express route you can add to your index.js:
```
// ...existing code...
const fetch = require('node-fetch'); // Add at the top if not already present
app.post('/send-to-sequence', async (req, res) => {
 try {
 const brokerURI = process.env.K_SINK || 'http://bookstore-broker.knativeeventing.svc.cluster.local'; // Use env or default
 const reviewText = req.body.reviewText || "Test review from node-server";
 const event = {
 specversion: "1.0",
 type: "new-review-comment",
 source: "node-server",
 id: Date.now().toString(),
 datacontenttype: "application/json",
 data: {
 reviewText: reviewText
 }
 };
 const response = await fetch(brokerURI, {
 method: 'POST',
 headers: {
 'Content-Type': 'application/cloudevents+json',
 },
 body: JSON.stringify(event),
 });
 if (!response.ok) {
 return res.status(500).json({error: 'Failed to send event to sequence'});
 }
 res.status(200).json({success: true, message: 'Event sent to sequence'});
 } catch (error) {
 res.status(500).json({error: 'Internal server error'});
 }
});
// ...existing code‚Ä¶
```
This will allow you to POST to /send-to-sequence with a JSON body like { "reviewText": "Hello
Sequence!" } and have the event routed through your Knative Sequence.
To create a service that receives these messages (CloudEvents from the Sequence) and saves them
to a file, you can use a simple Knative Service with a minimal HTTP server. Here‚Äôs how you can do
it:
1. Create a Dockerized Node.js Service
index.js:
```
const express = require('express');
const fs = require('fs');
const app = express();
const PORT = process.env.PORT || 8080;
app.use(express.json());
app.post('/', (req, res) => {
 // Save the received event to a file (append mode)
 fs.appendFileSync('/data/events.log', JSON.stringify(req.body) + '\n');
 res.status(200).send('Event saved');
});
app.listen(PORT, () => {
 console.log(`File sink service listening on port ${PORT}`);
});
```
dokckerfile:
```
FROM node:18-alpine
WORKDIR /app
COPY index.js .
RUN npm install express
VOLUME ["/data"]
CMD ["node", "index.js"]
```
2. Build and Push the Image
```
docker build -t <your-dockerhub-username>/file-sink:latest .
docker push <your-dockerhub-username>/file-sink:latest
```
3. Deploy as a Knative Service
file-sink.yaml:
```
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
 name: file-sink
spec:
 template:
 spec:
 containers:
 - image: <your-dockerhub-username>/file-sink:latest
 volumeMounts:
 - name: data
 mountPath: /data
 volumes:
 - name: data
 emptyDir: {}
```
Apply with:
kubectl apply -f file-sink.yaml
4. Route Events to the Service
Create a Trigger or set the Sequence‚Äôs reply to point to this service, e.g.:
reply:
 ref:
 apiVersion: serving.knative.dev/v1
 kind: Service
 name: file-sink
Or use a Trigger to route from the broker to file-sink.
Summary:
The service receives HTTP POSTs (CloudEvents), appends them to /data/events.log.
Deploy as a Knative Service.
Route events to it from your Sequence or Broker.
Let me know if you want a ready-to-use YAML or more details!

-----
## U≈ºycie AI do radzenia sobie z b≈Çƒôdami

W tym projekcie narzƒôdzia AI by≈Çy czƒôsto wykorzystywane w ten spos√≥b. Spisanie wszystkich takich prompt√≥w ma ograniczony sens wiƒôc postanowili≈õmy przedstawiƒá tylko jeden, przyk≈Çadowy prompt:

### Prompt:
```
I've rebuilt my image:
eval $(minikube docker-env)
docker build -t file-sink:latest .
docker tag file-sink:latest dev.local/file-sink:latest


and I wanted to reapply the configuration so a new image gets pulled:
kn service apply file-sink --image=dev.local/file-sink --pull-policy=Never
but I got:

No changes to apply to service 'file-sink'
```

Odpowied≈∫:


The message:

```
No changes to apply to service 'file-sink'
```

means that `kn service apply` detected no difference between the existing service and the new one you're trying to apply ‚Äî so it skips any update.

This happens even if you've rebuilt the image, because Knative identifies the image by its reference (`dev.local/file-sink`) ‚Äî **not by its content**. Since you're using `--pull-policy=Never`, it expects the image to be locally available and doesn't try to fetch a newer version.

### ‚úÖ Solutions

#### üîÅ Option 1: Force an update by changing the image reference

Add a **dummy tag** (like a timestamp or version bump) to ensure `kn` detects a change:

```bash
NEW_TAG="dev.local/file-sink:$(date +%s)"
docker tag file-sink:latest $NEW_TAG
kn service apply file-sink --image=$NEW_TAG --pull-policy=Never
```

This tricks Knative into thinking it's a different image, even though it's actually the same one locally.

---

#### üîÑ Option 2: Delete and recreate the service (not always ideal)

If you don‚Äôt mind downtime or losing service state:

```bash
kn service delete file-sink
kn service create file-sink --image=dev.local/file-sink:latest --pull-policy=Never
```

---

#### üîÑ Option 3: Use `kn service update` instead

Sometimes `kn service update` forces a new revision even when `apply` doesn't:

```bash
kn service update file-sink --image=dev.local/file-sink:latest --pull-policy=Never
```

This can trigger a rollout without needing to change the tag.

---

Let me know if you want to automate this tagging or update it directly in your build script.


---------------------------------------
### Prompt:

\# HELP process_cpu_user_seconds_total Total user CPU time spent in seconds.

  ...

\# TYPE db_query_duration_seconds histogram

–Ω–∞–ø–∏—à–∏ –º–µ–Ω—ñ –¥–µ–∫—ñ–ª–∫–∞ PomQL —Å–∫—Ä–∏–ø—Ç—ñ–≤ –¥–ª—è –≥—Ä–∞—Ñ–∞–Ω–∏ —â–æ–± –≤—ñ–¥–æ–±—Ä–∞–∂–∞—Ç–∏ —â–µ 4 –º–µ—Ç—Ä–∏–∫–∏ –æ–∫—Ä—ñ–º HTTP request count —ñ heap memory usage

### Odpowied≈∫:

–û—Å—å –∫—ñ–ª—å–∫–∞ PromQL —Å–∫—Ä–∏–ø—Ç—ñ–≤ –¥–ª—è Grafana, —è–∫—ñ –¥–æ–ø–æ–º–æ–∂—É—Ç—å –≤–∞–º –≤—ñ–¥–æ–±—Ä–∞–∑–∏—Ç–∏ —â–µ 4 –º–µ—Ç—Ä–∏–∫–∏, –∫—Ä—ñ–º –∫—ñ–ª—å–∫–æ—Å—Ç—ñ HTTP-–∑–∞–ø–∏—Ç—ñ–≤ —Ç–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–∞–º'—è—Ç—ñ –∫—É–ø–∏:

1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è CPU –ø—Ä–æ—Ü–µ—Å—É (—É –≤—ñ–¥—Å–æ—Ç–∫–∞—Ö)
–¶—è –º–µ—Ç—Ä–∏–∫–∞ –ø–æ–∫–∞–∑—É—î, —è–∫–∏–π –≤—ñ–¥—Å–æ—Ç–æ–∫ CPU –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –≤–∞—à Node.js –ø—Ä–æ—Ü–µ—Å. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ rate –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É —à–≤–∏–¥–∫–æ—Å—Ç—ñ –∑–º—ñ–Ω–∏ –ª—ñ—á–∏–ª—å–Ω–∏–∫–∞ process_cpu_seconds_total –∑–∞ –ø–µ–≤–Ω–∏–π –ø—Ä–æ–º—ñ–∂–æ–∫ —á–∞—Å—É (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 5 —Ö–≤–∏–ª–∏–Ω) —ñ –º–Ω–æ–∂–∏–º–æ –Ω–∞ 100, —â–æ–± –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤—ñ–¥—Å–æ—Ç–∫–∏.

``` bash
rate(process_cpu_seconds_total[5m]) * 100
```

–û–ø–∏—Å: –í—ñ–¥—Å–æ—Ç–æ–∫ CPU, —è–∫–∏–π –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –≤—ñ–¥—Å—Ç–µ–∂—É–≤–∞–Ω–∏–π –ø—Ä–æ—Ü–µ—Å.
–¢–∏–ø –ø–∞–Ω–µ–ª—ñ Grafana: Graph
–ü—Ä–∏–º—ñ—Ç–∫–∞: –¶–µ –ø–æ–∫–∞–∑—É—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è CPU –æ–¥–Ω–∏–º –ø—Ä–æ—Ü–µ—Å–æ–º. –Ø–∫—â–æ —É –≤–∞—Å —î –∫—ñ–ª—å–∫–∞ —ñ–Ω—Å—Ç–∞–Ω—Å—ñ–≤ –ø—Ä–æ–≥—Ä–∞–º–∏, –≤–∏ –º–æ–∂–µ—Ç–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ sum by (instance) –∞–±–æ avg by (instance) –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü—ñ—ó.
2. –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω–∏—Ö —Ä–µ—Å—É—Ä—Å—ñ–≤ Node.js
–¶—è –º–µ—Ç—Ä–∏–∫–∞ –ø–æ–∫–∞–∑—É—î –∑–∞–≥–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω–∏—Ö —Ä–µ—Å—É—Ä—Å—ñ–≤, —è–∫—ñ –ø—ñ–¥—Ç—Ä–∏–º—É—é—Ç—å —Ä–æ–±–æ—Ç—É —Ü–∏–∫–ª—É –ø–æ–¥—ñ–π (event loop) Node.js. –¶–µ –º–æ–∂—É—Ç—å –±—É—Ç–∏ –≤—ñ–¥–∫—Ä–∏—Ç—ñ —Ñ–∞–π–ª–∏, —Å–æ–∫–µ—Ç–∏ —Ç–æ—â–æ.

``` bash
nodejs_active_resources_total
```

–û–ø–∏—Å: –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω–∏—Ö —Ä–µ—Å—É—Ä—Å—ñ–≤ Node.js.
–¢–∏–ø –ø–∞–Ω–µ–ª—ñ Grafana: Single Stat –∞–±–æ Graph (—è–∫—â–æ –≤–∏ —Ö–æ—á–µ—Ç–µ –±–∞—á–∏—Ç–∏ —Ç—Ä–µ–Ω–¥).
–ü—Ä–∏–º—ñ—Ç–∫–∞: –í–∏ —Ç–∞–∫–æ–∂ –º–æ–∂–µ—Ç–µ —Ä–æ–∑–±–∏—Ç–∏ —Ü–µ –∑–∞ —Ç–∏–ø–æ–º —Ä–µ—Å—É—Ä—Å—É, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ nodejs_active_resources. –ù–∞–ø—Ä–∏–∫–ª–∞–¥, –¥–ª—è –ø–µ—Ä–µ–≥–ª—è–¥—É –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –∞–∫—Ç–∏–≤–Ω–∏—Ö —Å–æ–∫–µ—Ç—ñ–≤: nodejs_active_resources{type="TCPSocketWrap"}
3. –ú–µ–¥—ñ–∞–Ω–∞ –∑–∞—Ç—Ä–∏–º–∫–∏ —Ü–∏–∫–ª—É –ø–æ–¥—ñ–π (Event Loop Lag P50)
–ó–∞—Ç—Ä–∏–º–∫–∞ —Ü–∏–∫–ª—É –ø–æ–¥—ñ–π —î –∫—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–ª–∏–≤–æ—é –º–µ—Ç—Ä–∏–∫–æ—é –¥–ª—è Node.js, –æ—Å–∫—ñ–ª—å–∫–∏ –≤–æ–Ω–∞ –ø–æ–∫–∞–∑—É—î, –Ω–∞—Å–∫—ñ–ª—å–∫–∏ —à–≤–∏–¥–∫–æ Node.js –º–æ–∂–µ –æ–±—Ä–æ–±–ª—è—Ç–∏ –ø–æ–¥—ñ—ó. P50 (50-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å, –∞–±–æ –º–µ–¥—ñ–∞–Ω–∞) –¥–∞—î –≥–∞—Ä–Ω–µ —É—è–≤–ª–µ–Ω–Ω—è –ø—Ä–æ —Ç–∏–ø–æ–≤—É –∑–∞—Ç—Ä–∏–º–∫—É.

``` bash
nodejs_eventloop_lag_p50_seconds
```

–û–ø–∏—Å: 50-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å –∑–∞—Ç—Ä–∏–º–∫–∏ —Ü–∏–∫–ª—É –ø–æ–¥—ñ–π Node.js (—É —Å–µ–∫—É–Ω–¥–∞—Ö).
–¢–∏–ø –ø–∞–Ω–µ–ª—ñ Grafana: Graph –∞–±–æ Single Stat.
–ü—Ä–∏–º—ñ—Ç–∫–∞: –ß–∏–º –º–µ–Ω—à–µ –∑–Ω–∞—á–µ–Ω–Ω—è, —Ç–∏–º –∫—Ä–∞—â–µ. –í–µ–ª–∏–∫—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –º–æ–∂—É—Ç—å —Å–≤—ñ–¥—á–∏—Ç–∏ –ø—Ä–æ –±–ª–æ–∫—É–≤–∞–Ω–Ω—è —Ü–∏–∫–ª—É –ø–æ–¥—ñ–π.
4. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∑–æ–≤–Ω—ñ—à–Ω—å–æ—ó –ø–∞–º'—è—Ç—ñ Node.js (—É –º–µ–≥–∞–±–∞–π—Ç–∞—Ö)
–¶—è –º–µ—Ç—Ä–∏–∫–∞ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—î –æ–±—Å—è–≥ –ø–∞–º'—è—Ç—ñ, –≤–∏–¥—ñ–ª–µ–Ω–æ—ó Node.js –ø–æ–∑–∞ –∫—É–ø–æ—é V8. –¶–µ –º–æ–∂–µ –±—É—Ç–∏ –ø–∞–º'—è—Ç—å, —â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –±—É—Ñ–µ—Ä–∞–º–∏, –Ω–∞—Ç–∏–≤–Ω–∏–º–∏ –º–æ–¥—É–ª—è–º–∏ —Ç–æ—â–æ.

``` bash
nodejs_external_memory_bytes / (1024 * 1024)
```

–û–ø–∏—Å: –†–æ–∑–º—ñ—Ä –∑–æ–≤–Ω—ñ—à–Ω—å–æ—ó –ø–∞–º'—è—Ç—ñ Node.js —É –º–µ–≥–∞–±–∞–π—Ç–∞—Ö.
–¢–∏–ø –ø–∞–Ω–µ–ª—ñ Grafana: Graph –∞–±–æ Single Stat.
–ü—Ä–∏–º—ñ—Ç–∫–∞: –í–∞–∂–ª–∏–≤–æ –≤—ñ–¥—Å—Ç–µ–∂—É–≤–∞—Ç–∏ —Ü—é –º–µ—Ç—Ä–∏–∫—É, –æ—Å–∫—ñ–ª—å–∫–∏ –≤–æ–Ω–∞ –º–æ–∂–µ –∑—Ä–æ—Å—Ç–∞—Ç–∏ –Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∫—É–ø–∏ V8.
–¶—ñ PromQL —Å–∫—Ä–∏–ø—Ç–∏ –¥–∞–¥—É—Ç—å –≤–∞–º –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —ñ–Ω—Å–∞–π—Ç–∏ —É –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å –≤–∞—à–æ—ó Node.js –ø—Ä–æ–≥—Ä–∞–º–∏ –≤ Grafana. –ù–µ –∑–∞–±—É–¥—å—Ç–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ —Ç–∏–ø–∏ –ø–∞–Ω–µ–ª–µ–π (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "Graph" –¥–ª—è —Ç—Ä–µ–Ω–¥—ñ–≤ –∞–±–æ "Single Stat" –¥–ª—è –ø–æ—Ç–æ—á–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å) —Ç–∞ –æ–¥–∏–Ω–∏—Ü—ñ –≤–∏–º—ñ—Ä—É –≤ Grafana –¥–ª—è –∫—Ä–∞—â–æ—ó –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó.


---------------------------------------

### Prompt:
(base) usr@usr:/mnt/c/Users/123gh/pythonProjects/suu-project$ kubectl logs file-sink-00001-deployment-6d98f85976-2b2nn

'Defaulted container "user-container" out of: user-container, queue-proxy

/app/file-sink-tracing.js:15

¬† resource: new Resource({

¬† ¬† ¬† ¬† ¬† ¬† ^



TypeError: Resource is not a constructor

¬† ¬† at Object.<anonymous> (/app/file-sink-tracing.js:15:13)

¬† ¬† at Module._compile (node:internal/modules/cjs/loader:1364:14)

...

EXPOSE 8080


CMD ["node", "-r", "./file-sink-tracing.js", "index.js"]

—è–∫ —Ç–æ –ø–æ—Ñ—ñ–∫—Å–∏—Ç–∏

### Odpowied≈∫:

–ü—Ä–∏–≤—ñ—Ç! –°—Ö–æ–∂–µ, –≤–∏ –∑—ñ—Ç–∫–Ω—É–ª–∏—Å—è –∑ –ø–æ—à–∏—Ä–µ–Ω–æ—é –ø—Ä–æ–±–ª–µ–º–æ—é –ø—ñ–¥ —á–∞—Å –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è OpenTelemetry –≤ Node.js.

–ü–æ–º–∏–ª–∫–∞ TypeError: Resource is not a constructor –º–∞–π–∂–µ –∑–∞–≤–∂–¥–∏ –≤–∫–∞–∑—É—î –Ω–∞ –∫–æ–Ω—Ñ–ª—ñ–∫—Ç –∞–±–æ –Ω–µ—Å—É–º—ñ—Å–Ω—ñ—Å—Ç—å –≤–µ—Ä—Å—ñ–π –º—ñ–∂ —Ä—ñ–∑–Ω–∏–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏ @opentelemetry/*, —è–∫—ñ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ñ —É –≤–∞—à–æ–º—É –ø—Ä–æ—î–∫—Ç—ñ.

–í–∞—à –∫–æ–¥ —É file-sink-tracing.js –Ω–∞–ø–∏—Å–∞–Ω–∏–π –ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–ª—è —Å—É—á–∞—Å–Ω–∏—Ö –≤–µ—Ä—Å—ñ–π OpenTelemetry. –ü—Ä–æ–±–ª–µ–º–∞ –ø–æ–ª—è–≥–∞—î –Ω–µ –≤ —Å–∞–º–æ–º—É –∫–æ–¥—ñ, –∞ –≤ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—è—Ö, —è–∫—ñ –≤—Å—Ç–∞–Ω–æ–≤–ª—é—é—Ç—å—Å—è —É –≤–∞—à Docker-–æ–±—Ä–∞–∑. –ù–∞–π—ñ–º–æ–≤—ñ—Ä–Ω—ñ—à–µ, –∫–æ–ø—ñ—é—î—Ç—å—Å—è —Å—Ç–∞—Ä–∏–π —Ñ–∞–π–ª package-lock.json –∞–±–æ –≤—Å—Ç–∞–Ω–æ–≤–ª—é—é—Ç—å—Å—è –Ω–µ—Å—É–º—ñ—Å–Ω—ñ –º—ñ–∂ —Å–æ–±–æ—é –≤–µ—Ä—Å—ñ—ó –ø–∞–∫–µ—Ç—ñ–≤.

–Ø–∫ —Ü–µ –≤–∏–ø—Ä–∞–≤–∏—Ç–∏
–ù–∞–π–±—ñ–ª—å—à –Ω–∞–¥—ñ–π–Ω–∏–π —Å–ø–æ—Å—ñ–± ‚Äî —Ü–µ –∑–∞–±–µ–∑–ø–µ—á–∏—Ç–∏, —â–æ–± —É—Å—ñ –ø–∞–∫–µ—Ç–∏ OpenTelemetry –±—É–ª–∏ —Å–≤—ñ–∂–∏—Ö —Ç–∞ —Å—É–º—ñ—Å–Ω–∏—Ö –≤–µ—Ä—Å—ñ–π.

–ö—Ä–æ–∫ 1: –û–Ω–æ–≤—ñ—Ç—å –≤–µ—Ä—Å—ñ—ó —É package.json

–í—ñ–¥–∫—Ä–∏–π—Ç–µ –≤–∞—à —Ñ–∞–π–ª package.json —Ç–∞ –≤—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –¥–ª—è –ø–∞–∫–µ—Ç—ñ–≤ OpenTelemetry –≤–µ—Ä—Å—ñ—ó –∑ –æ–¥–Ω–æ–≥–æ —Å—É–º—ñ—Å–Ω–æ–≥–æ –≤–∏–ø—É—Å–∫—É. –¶–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–ª–∏–≤–æ –¥–ª—è —ó—Ö–Ω—å–æ—ó —Å—Ç–∞–±—ñ–ª—å–Ω–æ—ó —Ä–æ–±–æ—Ç–∏.

–û—Å—å –ø—Ä–∏–∫–ª–∞–¥ —Å—É–º—ñ—Å–Ω–∏—Ö –≤–µ—Ä—Å—ñ–π, —è–∫—ñ –≤–∏ –º–æ–∂–µ—Ç–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏:

``` JSON
"dependencies": {
  "@opentelemetry/api": "^1.8.0",
  "@opentelemetry/auto-instrumentations-node": "^0.47.0",
  "@opentelemetry/exporter-trace-otlp-http": "^0.51.0",
  "@opentelemetry/resources": "^1.25.0",
  "@opentelemetry/sdk-node": "^0.51.0",
  "@opentelemetry/semantic-conventions": "^1.25.0",
  "express": "^4.19.2"
}
```

–ö—Ä–æ–∫ 2: –í–∏–∫–æ–Ω–∞–π—Ç–µ —á–∏—Å—Ç—É —É—Å—Ç–∞–Ω–æ–≤–∫—É –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π

–©–æ–± –≥–∞—Ä–∞–Ω—Ç–æ–≤–∞–Ω–æ –ø–æ–∑–±—É—Ç–∏—Å—è —Å—Ç–∞—Ä–∏—Ö –∞–±–æ –∫–æ–Ω—Ñ–ª—ñ–∫—Ç–Ω–∏—Ö –ø–∞–∫–µ—Ç—ñ–≤, –≤–∏–¥–∞–ª—ñ—Ç—å –ø–∞–ø–∫—É node_modules —ñ —Ñ–∞–π–ª package-lock.json –∑ –≤–∞—à–æ–≥–æ –ø—Ä–æ—î–∫—Ç—É –ª–æ–∫–∞–ª—å–Ω–æ.

```Bash
rm -rf node_modules package-lock.json
```

–ü–æ—Ç—ñ–º –∑–∞–ø—É—Å—Ç—ñ—Ç—å —É—Å—Ç–∞–Ω–æ–≤–∫—É –∑–∞–Ω–æ–≤–æ. –¶–µ —Å—Ç–≤–æ—Ä–∏—Ç—å –Ω–æ–≤–∏–π, –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∏–π —Ñ–∞–π–ª package-lock.json –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤–µ—Ä—Å—ñ–π, —è–∫—ñ –≤–∏ –≤–∫–∞–∑–∞–ª–∏ –≤ package.json.

```Bash
npm install
```

–ö—Ä–æ–∫ 3: –ü–µ—Ä–µ–∑–±–µ—Ä—ñ—Ç—å –≤–∞—à Docker-–æ–±—Ä–∞–∑

–¢–µ–ø–µ—Ä, –∫–æ–ª–∏ —É –≤–∞—Å —î –æ–Ω–æ–≤–ª–µ–Ω—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ —Ç–∞ –Ω–æ–≤–∏–π package-lock.json, –ø–µ—Ä–µ–∑–±–µ—Ä—ñ—Ç—å Docker-–æ–±—Ä–∞–∑. –û—Å–∫—ñ–ª—å–∫–∏ –≤–∞—à Dockerfile –∫–æ–ø—ñ—é—î package*.json, –≤—ñ–Ω –ø—ñ–¥—Ö–æ–ø–∏—Ç—å —ñ –Ω–æ–≤–∏–π –ª–æ–∫-—Ñ–∞–π–ª.

```Bash
docker build -t file-sink-service .
```

–ü—ñ—Å–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è —Ü–∏—Ö –∫—Ä–æ–∫—ñ–≤ –≤–∞—à Docker-–æ–±—Ä–∞–∑ –±—É–¥–µ –º—ñ—Å—Ç–∏—Ç–∏ —É–∑–≥–æ–¥–∂–µ–Ω—ñ –≤–µ—Ä—Å—ñ—ó –ø–∞–∫–µ—Ç—ñ–≤, —ñ –ø–æ–º–∏–ª–∫–∞ TypeError –º–∞—î –∑–Ω–∏–∫–Ω—É—Ç–∏.

---------------------------------------


# Podsumowanie i wnioski

Podczas realizacji projektu napotkali≈õmy istotne trudno≈õci zwiƒÖzane z konfiguracjƒÖ oryginalnej aplikacji demonstracyjnej Knative Bookstore. G≈Ç√≥wnym problemem by≈Ç brak aktywnego rozwoju tej aplikacji, co skutkowa≈Ço niekompatybilno≈õciƒÖ wersji, przestarza≈Çymi zale≈ºno≈õciami i nieaktualnƒÖ dokumentacjƒÖ. 

Ze smutkiem wspominamy ka≈ºdƒÖ godzinƒô po≈õwiƒôconƒÖ na pr√≥bƒô otworzenia oryginalnej aplikacji, zanim zorientowali≈õmy siƒô ≈ºe to nie jest optymalne podej≈õcie, ale liczymy ≈ºe ka≈ºda z tych godzin dosadniej u≈õwiadomi≈Ça nam jak wa≈ºne jest ca≈Ço≈õciowe i krytyczne spojrzenie na projekt.

Kluczowe okaza≈Ço siƒô skupienie na rzeczywistej istocie projektu ‚Äì telemetri, demonstracji mechanizm√≥w event-driven, oraz dodatkowo obs≈Çugi b≈Çƒôd√≥w w Knative ‚Äì zamiast wiernego odtwarzania ka≈ºdego elementu oryginalnej architektury. W przypadku problem√≥w konfiguracyjnych upro≈õcili≈õmy rozwiƒÖzanie, zastƒôpujƒÖc problematyczne serwisy w≈Çasnymi, prostszymi komponentami. Takie podej≈õcie pozwoli≈Ço nam nie tylko uko≈Ñczyƒá projekt, ale tak≈ºe lepiej zrozumieƒá kluczowe mechanizmy Knative i praktyczne aspekty wdra≈ºania rozwiƒÖza≈Ñ serverless oraz event-driven w Kubernetes. 

Uda≈Ço siƒô skutecznie wdro≈ºyƒá system observability z wykorzystaniem OpenTelemetry, Prometheusa i Grafany. By≈Ço to kszta≈ÇcƒÖce do≈õwiadczenie, kt√≥re pozwoli≈Ço nam w praktyce poznaƒá, jak dzia≈ÇajƒÖ narzƒôdzia do monitorowania i ≈õledzenia przep≈Çywu zdarze≈Ñ w architekturze event-driven. Dziƒôki temu mogli≈õmy lepiej zrozumieƒá zar√≥wno techniczne aspekty wdro≈ºenia, jak i korzy≈õci p≈ÇynƒÖce z monitorowania rozproszonych system√≥w.

# **Podzia≈Ç zada≈Ñ**

* modyfikacja aplikacji: symulacja b≈Çƒôd√≥w w us≈Çudze Slack Sink i obs≈Çuga b≈Çƒôd√≥w (2 os.)  
* itegracja aplikacji z OTel  
* integracja z GrafanƒÖ
